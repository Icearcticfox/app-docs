{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"Chef/","title":"Chef","text":""},{"location":"Chef/#example-test-vm-cookbook-with-mock-parameters","title":"Example test VM cookbook with mock parameters","text":"<p>run in directory <code>&lt;cookbooks&gt;/spec/&lt;&gt;.rb</code></p> <pre><code>require 'chefspec'  \n\n\nclass File  \n  def self.exists?(path)  \n    exist?(path)  \n  end  \nend  \n\n\n\nmodule PerimeterHelper  \n  def self.preprod?  \n    'test'  \n  end  \n\n  def self.environment  \n    'preprod'  \n  end  \n\n  def self.under_test?  \n    true  \n  end  \nend  \n\n\nmodule CriteoInfra  \n  module Device  \n    def self.owners  \n      'gu-tests'  \n    end  \n  end  \n\n  def self.datacenter  \n    'datacenter-1'  \n  end  \n\n  def self.environment  \n    'preprod'  \n  end  \nend  \n\nRSpec.configure do |config|  \n  config.cookbook_path = [  \n    '../chef-configuration/policies/observability/victoriametrics/cookbooks/',  \n    '../chef-configuration/policies/observability/shared-cookbooks/',  \n    '../.chef-workstation/cache/cookbooks/',  \n    '../criteo/chef-configuration/policies/hardware/inventory/cookbooks/base-inventory/'  \n  ]  \n\n  config.before(:each) do  \n      vault_items = {  \n        ['secrets', 'victoriametrics_backup_preprod'] =&gt; { 'access_key' =&gt; 'mock_access_key', 'secret_key' =&gt; 'mock_secret_key' },  \n        ['secrets', 'consul_acl_storage_preprod'] =&gt; { 'consul_token' =&gt; 'mocked_consul_token' }  \n      }  \n      allow_any_instance_of(Chef::DSL::Secret).to receive(:chef_vault_item) do |instance, *args|  \n        puts \"chef_vault_item called with args: #{args.inspect}\"  \n        result = vault_items[args] || nil  \n        puts \"chef_vault_item called with args: #{args.inspect}, returning: #{result.inspect}\"  \n        result  \n    end  \n    allow_any_instance_of(Chef::DSL::Secret).to receive(:secret)  \n      .and_return('consul_criteo' =&gt; { 'acl_token' =&gt; 'mocked_acl_token' })  \n\n    stub_const('CriteoBase', Module.new)  \n    stub_const('CriteoBase::DNS', Module.new)  \n\n    allow(CriteoBase::DNS).to receive(:service_zone).and_return('default_service_zone')  \n    allow(CriteoBase::DNS).to receive_message_chain(:consul_alias).and_return(nil)  \n  end  \nend  \n\n\ndescribe 'policy-victoriametrics::default' do  \n  let(:env) { 'preprod' }  \n  before do  \n    allow(::CriteoInfra).to receive(:environment).and_return(env)  \n    allow_any_instance_of(Chef::DSL::Secret).to receive(:chef_vault_item).and_call_original  \n\n    expect_any_instance_of(Chef::DSL::Secret).to receive(:chef_vault_item)  \n      .with('secrets', \"consul_acl_storage_#{env}\")  \n      .and_return('consul_token' =&gt; 'mocked_consul_token')  \n  end  \n\n  let(:chef_run) do  \n    # Creating a simulation of chef-client execution with the necessary attributes  \n    ChefSpec::SoloRunner.new(platform: 'ubuntu', version: '18.04') do |node|  \n      node.normal['victoriametrics']['vmagent']['enabled'] = true  \n      node.normal['victoriametrics']['vmagent']['custom_flags'] = '--some-flag'  \n      node.normal['victoriametrics']['vmagent']['http_address'] = ':8429'  \n      node.normal['victoriametrics']['vmagent']['graphite_address'] = ':2003'  \n      node.normal['victoriametrics']['vmagent']['spool_dir'] = '/opt/vmagent/spool'  \n      node.normal['victoriametrics']['vmagent']['memory_allowed_percent'] = 60  \n      node.normal['victoriametrics']['vmagent']['remotewrite_show_url'] = true  \n      node.normal['victoriametrics']['vmagent']['remotewrite_queues'] = 80  \n      node.normal['victoriametrics']['vmagent']['remotewrite_max_block_size'] = 83886080  \n      node.normal['consul_criteo']['acl_token'] = 'mocked_acl_token'  \n      node.normal['os_criteo']['hostname'] = 'mocked-hostname'  \n      node.normal['victoriametrics']['vmagent']['remotewrite_max_rows_per_block'] = 100000  \n      node.normal['victoriametrics']['vmagent']['spool_max_disk_usage'] = 48  \n      node.normal['victoriametrics']['vmagent']['remotewrite_multitenant'] = [  \n        { 'url' =&gt; \"http://testconsul\", 'relabel_type' =&gt; 'short', 'diskSpooling' =&gt; false }  \n      ]  \n    end.converge('policy-victoriametrics::service')  \n  end  \n\n  before do  \n    chef_run.resource_collection.insert(  \n      Chef::Resource::Service.new('consul', chef_run.run_context)  \n    )  \n  end  \n\n  it 'creates the correct command for vmagent' do  \n  expected_params = \"--some-flag \" \\  \n                    \"--httpListenAddr=:8429 \" \\  \n                    \"--graphiteListenAddr=:2003 \" \\  \n                    \"--remoteWrite.tmpDataPath=/opt/vmagent/spool \" \\  \n                    \"--memory.allowedPercent=60 \" \\  \n                    \"--remoteWrite.showURL=true \" \\  \n                    \"--remoteWrite.queues=80 \" \\  \n                    \"--remoteWrite.maxBlockSize=83886080 \" \\  \n                    \"--remoteWrite.maxRowsPerBlock=100000 \" \\  \n                    \"--remoteWrite.maxDiskUsagePerURL=48GB \" \\  \n                    \"--remoteWrite.url=http://testconsul \" \\  \n                    \"--remoteWrite.urlRelabelConfig=/opt/vmagent/conf/rw_relabel_short.yml \" \\  \n                    '--remoteWrite.disableOnDiskQueue=true '  \n\n  actual_params = chef_run.node['services']['vmagent']['params']  \n\n  puts \"Expected: #{expected_params.inspect}\"  \n  puts \"Actual: #{actual_params.inspect}\"  \n\n  expect(actual_params.strip).to eq(expected_params.strip)  \nend  \nend\n</code></pre>"},{"location":"psql/","title":"Psql","text":"<p>timescaledb</p> <p>`SELECT * FROM timescaledb_information.hypertables;</p> <p>`SELECT show_chunks('history', older_than =&gt; (EXTRACT(epoch FROM NOW()) - (60 * 60 * 24 * 1))::integer);</p> <p>https://chat.openai.com/share/c720a5b0-941e-4a3b-8fff-10ccaeb7aa9f</p> <p>pid removing</p> <p>`ps aux | grep \u201cSELECT waiting\u201d | awk \u2018{print $2}\u2019 | sed \u2018s/^/SELECT pg_cancel_backend(/g\u2019 | sed \u2018s/$/);/g\u2019</p> <p>`SELECT pg_cancel_backend(1737628);</p> <p>pqactivity</p> <pre><code>psql -h pgb-tcrm-customer.pgsql.tcsbank.ru -p 6432 -d database -U user -a -f 1.sql -o result_1.txt\n\npsql -h pgb-tcrm-registry.tcsbank.ru -p 6432 -U tcrm_acl -d database -c 'select * from acl.rule r inner join acl.group g on r.id = g.rule_id where http_methods &amp;&amp; '{\"POST\", \"DELETE\", \"PUT\"}' and entry_points &amp;&amp; '{\"wo-lb\"}';' -o result_1.csv\n\npsql -h pgb-tcrm-registry.tcsbank.ru -p 5432 -d database -U tcrm -c \u00abselect id, last_update, expiration_date, md5sum, access_mode, size, alias, file_path, owner, original_file_name, media_type, edit_mode, http_link, watermark, http_link_auth_code FROM file_storage.file_metadata WHERE expiration_date &gt; '2023-05-01 00:00:00' and last_update &gt; '2023-02-20 00:00:00\u2019\u00bb\n\npsql -h\u00a0 [pgb-tcrm-customer.pgsql.tcsbank.ru](http://pgb-tcrm-customer.pgsql.tcsbank.ru) -p 6432\u00a0 -d database -U tcrm_customer -c \u2018select * from public.customer_disability;\u2019 -o customer_prod_disability.csv\n</code></pre> <p>Creating user and schema</p> <pre><code>CREATE ROLE new_role WITH\n\nLOGIN\n\nNOSUPERUSER\n\nNOCREATEDB\n\nNOCREATEROLE\n\nINHERIT\n\nNOREPLICATION\n\nCONNECTION LIMIT -1\n\nPASSWORD \u2018****\u2019;\n\n\nCREATE SCHEMA \"schemaname\"\n\n\u00a0 \u00a0 AUTHORIZATION twork_entity;\n\nGRANT ALL ON SCHEMA \"ufebs_letters\" TO new_role;\n\n###GRANT ALL ON DATABASE db_name TO save_vars_from_background;\n\nGRANT CONNECT ON DATABASE db_name TO new_role;\n\nCREATE ROLE \"user_role\" WITH\n\nLOGIN\n\nNOSUPERUSER\n\nNOCREATEDB\n\nNOCREATEROLE\n\nINHERIT\n\nNOREPLICATION\n\nCONNECTION LIMIT -1\n\nPASSWORD 'passwd';\n\nGRANT CONNECT ON DATABASE dbname TO \"user\";\n\nGRANT USAGE ON SCHEMA schemaname TO \"user\";\n\nALTER DEFAULT PRIVILEGES IN SCHEMA schemaname\n\nGRANT SELECT ON TABLES TO \"user\";\n\nGRANT USAGE ON SCHEMA schemaname TO \"user\";\n\nALTER DEFAULT PRIVILEGES IN SCHEMA schemaname\n\nGRANT SELECT ON TABLES TO \"user\";\n</code></pre> <p>Select on all table in schema</p> <pre><code>GRANT SELECT ON ALL TABLES IN SCHEMA schemaname TO \"username\";\u00a0\n</code></pre> <p>Session removing</p> <pre><code>select pid from pg_stat_activity where state = 'idle';\n\nSELECT pg_terminate_backend(22779);\n</code></pre> <p>Dump</p> <pre><code>pg_dump -Fd --no-owner --host=hostname -p 6432 --username=username --dbname=dbname --schema=schema -j 1 --verbose -f /dumps/dump_file  \n\npg_restore -Fd --host=hostname -p 6432 --username=username --dbname=dbname -j 4 --verbose /dumps/dump_file\n\npg_restore --host=hostname -p 6432 --username=username --dbname=dbname -j 1 --verbose /dumps/dump_file  \n\n</code></pre> <p>Detect invalid indexes</p> <pre><code>SELECT * FROM pg_class, pg_index WHERE pg_index.indisvalid = false AND pg_index.indexrelid = pg_class.oid;\n</code></pre> <p>Create index</p> <p>Show progress:</p> <p>https://dba.stackexchange.com/questions/11329/monitoring-progress-of-index-construction-in-postgresql  </p> <pre><code>SELECT\n\n\u00a0 now()::TIME(0),\n\n\u00a0 a.query,\n\n\u00a0 p.phase,\n\n\u00a0 round(p.blocks_done / p.blocks_total::numeric * 100, 2) AS \"% done\",\n\n\u00a0 p.blocks_total,\n\n\u00a0 p.blocks_done,\n\n\u00a0 p.tuples_total,\n\n\u00a0 p.tuples_done,\n\n\u00a0 ai.schemaname,\n\n\u00a0 ai.relname,\n\n\u00a0 ai.indexrelname\n\nFROM pg_stat_progress_create_index p\n\nJOIN pg_stat_activity a ON p.pid = a.pid\n\nLEFT JOIN pg_stat_all_indexes ai on ai.relid = p.relid AND ai.indexrelid = p.index_relid;\n</code></pre> <p>Create index</p> <pre><code>CREATE INDEX CONCURRENTLY IF NOT EXISTS rev_info_revision_dttm_idx\n\nON rev_info(revision_dttm);\n</code></pre> <p>Get number of string in table</p> <pre><code>SELECT reltuples::bigint\n\nFROM pg_catalog.pg_class\n\nWHERE relname = \u2018table_name;\n</code></pre> <p>Table size</p> <pre><code>SELECT pg_size_pretty( pg_relation_size( \u2018table_name\u2019 ) );\n</code></pre>"},{"location":"rediscli/","title":"Rediscli","text":"<p>Delete all `redis-cli &gt; FLUSHALL ; zservice_server restart</p> <p>Get hash keys `hgetall ui-gce-va-1.broadsign.iponweb.net:zabbix_triggers\u00a0</p> <p>Get type of record `type ui-gce-va-1.broadsign.iponweb.net:zabbix_prototype_triggers\u00a0</p> <p>Get all keys with specified pattern `KEYS ui-gce-va-1*</p>"},{"location":"Basic-Skills/Git/","title":"Git","text":"<p>frequently used commands <code>git fetch origin staging</code>git reset --hard origin/staging</p> <p>gerrit 101</p> <p>Each commit creates a new patch, so it\u2019s necessary to update the current commit for new changes <code>git commit -m\u00a0\"Add feature XXX\"</code>git commit --amend --no-edit `git push origin HEAD:refs/for/master</p> <p>Get and checkout to specify commit message <code>git fetch origin 6937df5b42b2b0b9d56603cc95c28f5410b7adf6</code>git checkout 6937df5b42b2b0b9d56603cc95c28f5410b7adf6</p>"},{"location":"Basic-Skills/crontab/","title":"Crontab","text":""},{"location":"Basic-Skills/crontab/#crontab","title":"crontab","text":"<p>simple editor for cron schedule expressions</p> <p>Edit crontab <code>crontab -e</code> To view your crontab file (cron jobs) type: <code>crontab -l</code></p>"},{"location":"Basic-Skills/shell/","title":"Shell","text":""},{"location":"Basic-Skills/shell/#shell","title":"shell","text":"<p>Bash scripting cheatsheet <code>$@</code> - \u0440\u0430\u0441\u0448\u0438\u0440\u044f\u0435\u043c\u044b\u0439 \u0441\u043f\u0438\u0441\u043e\u043a \u043f\u043e\u0437\u0438\u0446\u0438\u043e\u043d\u043d\u044b\u0445 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u043d\u0430 \u0432\u0445\u043e\u0434 <code>$*</code> \u2014 \u044d\u0442\u043e \u043e\u0434\u0438\u043d \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440, \u0441\u043e\u0441\u0442\u043e\u044f\u0449\u0438\u0439 \u0438\u0437 \u0432\u0441\u0435\u0445 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432, \u0441\u043b\u043e\u0436\u0435\u043d\u043d\u044b\u0445 \u0432\u043c\u0435\u0441\u0442\u0435.</p>"},{"location":"Basic-Skills/shell/#_1","title":"\u0426\u0438\u043a\u043b\u044b","text":"<p>https://losst.ru/tsikly-bash</p> <ul> <li> <p>count=1; while [ $count -lt 5 ]; do echo \"\u0417\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0441\u0447\u0435\u0442\u0447\u0438\u043a\u0430: $count\"; count=$(( $count + 1 )); done  </p> </li> <li> <p>count=0; for ((i=1; i &lt; 5; i++)); do echo \"\u0417\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0441\u0447\u0435\u0442\u0447\u0438\u043a\u0430: $count\"; count=$(( $count + 1 )); done</p> </li> <li> <p>for ((;;)) do echo \"\u0411\u0435\u0441\u043a\u043e\u043d\u0435\u0447\u043d\u044b\u0439 \u0446\u0438\u043a\u043b, \u043d\u0430\u0436\u043c\u0438\u0442\u0435 CTRL+C \u0434\u043b\u044f \u0432\u044b\u0445\u043e\u0434\u0430\" done`  </p> </li> </ul> <p>\u041b\u043e\u0433\u0438\u0447\u0435\u0441\u043a\u0438\u0435 \u043e\u043f\u0435\u0440\u0430\u0442\u043e\u0440\u044b - -z # \u0441\u0442\u0440\u043e\u043a\u0430 \u043f\u0443\u0441\u0442\u0430 - -n # \u0441\u0442\u0440\u043e\u043a\u0430 \u043d\u0435 \u043f\u0443\u0441\u0442\u0430 - =, (==) # \u0441\u0442\u0440\u043e\u043a\u0438 \u0440\u0430\u0432\u043d\u044b - != # \u0441\u0442\u0440\u043e\u043a\u0438 \u043d\u0435\u0440\u0430\u0432\u043d\u044b - -eq # \u0440\u0430\u0432\u043d\u043e - -ne # \u043d\u0435\u0440\u0430\u0432\u043d\u043e - -lt,(&lt; ) # \u043c\u0435\u043d\u044c\u0448\u0435 - -le,(&lt;=) # \u043c\u0435\u043d\u044c\u0448\u0435 \u0438\u043b\u0438 \u0440\u0430\u0432\u043d\u043e - -gt,(&gt;) #\u0431\u043e\u043b\u044c\u0448\u0435 - -ge,(&gt;=) #\u0431\u043e\u043b\u044c\u0448\u0435 \u0438\u043b\u0438 \u0440\u0430\u0432\u043d\u043e - ! #\u043e\u0442\u0440\u0438\u0446\u0430\u043d\u0438\u0435 \u043b\u043e\u0433\u0438\u0447\u0435\u0441\u043a\u043e\u0433\u043e \u0432\u044b\u0440\u0430\u0436\u0435\u043d\u0438\u044f - -a,(&amp;&amp;) #\u043b\u043e\u0433\u0438\u0447\u0435\u0441\u043a\u043e\u0435 \u00ab\u0418\u00bb - -o,(||) # \u043b\u043e\u0433\u0438\u0447\u0435\u0441\u043a\u043e\u0435 \u00ab\u0418\u041b\u0418\u00bb</p>"},{"location":"Basic-Skills/web-service/","title":"Web service","text":"<p>Each of these commands will run an ad hoc http static server in your current (or specified) directory, available at http://localhost:8000. Use this power wisely.</p> <p>Discussion on reddit.</p>"},{"location":"Basic-Skills/web-service/#python-2x","title":"Python 2.x","text":"<pre><code>$ python -m SimpleHTTPServer 8000\n</code></pre>"},{"location":"Basic-Skills/web-service/#python-3x","title":"Python 3.x","text":"<pre><code>$ python -m http.server 8000\n</code></pre>"},{"location":"Basic-Skills/web-service/#twisted-python","title":"Twisted <sub><sup>(Python)</sup></sub>","text":"<pre><code>$ twistd -n web -p 8000 --path .\n</code></pre> <p>Or:</p> <pre><code>$ python -c 'from twisted.web.server import Site; from twisted.web.static import File; from twisted.internet import reactor; reactor.listenTCP(8000, Site(File(\".\"))); reactor.run()'\n</code></pre> <p>Depends on Twisted.</p>"},{"location":"Basic-Skills/web-service/#ruby","title":"Ruby","text":"<pre><code>$ ruby -rwebrick -e'WEBrick::HTTPServer.new(:Port =&gt; 8000, :DocumentRoot =&gt; Dir.pwd).start'\n</code></pre> <p>Credit: Barking Iguana</p>"},{"location":"Basic-Skills/web-service/#ruby-192","title":"Ruby 1.9.2+","text":"<pre><code>$ ruby -run -ehttpd . -p8000\n</code></pre> <p>Credit: nobu</p>"},{"location":"Basic-Skills/web-service/#adsf-ruby","title":"adsf <sub><sup>(Ruby)</sup></sub>","text":"<pre><code>$ gem install adsf   # install dependency\n$ adsf -p 8000\n</code></pre> <p>Credit: twome</p> <p>No directory listings.</p>"},{"location":"Basic-Skills/web-service/#sinatra-ruby","title":"Sinatra <sub><sup>(Ruby)</sup></sub>","text":"<pre><code>$ gem install sinatra   # install dependency\n$ ruby -rsinatra -e'set :public_folder, \".\"; set :port, 8000'\n</code></pre> <p>No directory listings.</p>"},{"location":"Basic-Skills/web-service/#perl","title":"Perl","text":"<pre><code>$ cpan HTTP::Server::Brick   # install dependency\n$ perl -MHTTP::Server::Brick -e '$s=HTTP::Server::Brick-&gt;new(port=&gt;8000); $s-&gt;mount(\"/\"=&gt;{path=&gt;\".\"}); $s-&gt;start'\n</code></pre> <p>Credit: Anonymous Monk</p>"},{"location":"Basic-Skills/web-service/#plack-perl","title":"Plack <sub><sup>(Perl)</sup></sub>","text":"<pre><code>$ cpan Plack   # install dependency\n$ plackup -MPlack::App::Directory -e 'Plack::App::Directory-&gt;new(root=&gt;\".\");' -p 8000\n</code></pre> <p>Credit: miyagawa</p>"},{"location":"Basic-Skills/web-service/#mojolicious-perl","title":"Mojolicious <sub><sup>(Perl)</sup></sub>","text":"<pre><code>$ cpan Mojolicious::Lite   # install dependency\n$ perl -MMojolicious::Lite -MCwd -e 'app-&gt;static-&gt;paths-&gt;[0]=getcwd; app-&gt;start' daemon -l http://*:8000\n</code></pre> <p>No directory listings.</p>"},{"location":"Basic-Skills/web-service/#http-server-nodejs","title":"http-server <sub><sup>(Node.js)</sup></sub>","text":"<pre><code>$ npm install -g http-server   # install dependency\n$ http-server -p 8000\n</code></pre> <p>Note: This server does funky things with relative paths. For example, if you have a file <code>/tests/index.html</code>, it will load <code>index.html</code> if you go to <code>/test</code>, but will treat relative paths as if they were coming from <code>/</code>.</p>"},{"location":"Basic-Skills/web-service/#node-static-nodejs","title":"node-static <sub><sup>(Node.js)</sup></sub>","text":"<pre><code>$ npm install -g node-static   # install dependency\n$ static -p 8000\n</code></pre> <p>No directory listings.</p>"},{"location":"Basic-Skills/web-service/#php-54","title":"PHP <sub><sup>(&gt;= 5.4)</sup></sub>","text":"<pre><code>$ php -S 127.0.0.1:8000\n</code></pre> <p>Credit: /u/prawnsalad and MattLicense</p> <p>No directory listings.</p>"},{"location":"Basic-Skills/web-service/#erlang","title":"Erlang","text":"<pre><code>$ erl -s inets -eval 'inets:start(httpd,[{server_name,\"NAME\"},{document_root, \".\"},{server_root, \".\"},{port, 8000},{mime_types,[{\"html\",\"text/html\"},{\"htm\",\"text/html\"},{\"js\",\"text/javascript\"},{\"css\",\"text/css\"},{\"gif\",\"image/gif\"},{\"jpg\",\"image/jpeg\"},{\"jpeg\",\"image/jpeg\"},{\"png\",\"image/png\"}]}]).'\n</code></pre> <p>Credit: nivertech (with the addition of some basic mime types)</p> <p>No directory listings.</p>"},{"location":"Basic-Skills/web-service/#busybox-httpd","title":"busybox httpd","text":"<pre><code>$ busybox httpd -f -p 8000\n</code></pre> <p>Credit: lvm</p>"},{"location":"Basic-Skills/web-service/#webfs","title":"webfs","text":"<pre><code>$ webfsd -F -p 8000\n</code></pre> <p>Depends on webfs.</p>"},{"location":"Basic-Skills/web-service/#iis-express","title":"IIS Express","text":"<pre><code>C:\\&gt; \"C:\\Program Files (x86)\\IIS Express\\iisexpress.exe\" /path:C:\\MyWeb /port:8000\n</code></pre> <p>Depends on IIS Express.</p> <p>Credit: /u/fjantomen</p> <p>No directory listings. <code>/path</code> must be an absolute path.</p>"},{"location":"Basic-Skills/web-service/#meta","title":"Meta","text":"<p>If you have any suggestions, drop them in the comments below or on the reddit discussion. To get on this list, a solution must:</p> <ol> <li>serve static files using your current directory (or a specified directory) as the server root,</li> <li>be able to be run with a single, one line command (dependencies are fine if they're a one-time thing),</li> <li>serve basic file types (html, css, js, images) with proper mime types,</li> <li>require no configuration (from files or otherwise) beyond the command itself (no framework-specific servers, etc)</li> <li>must run, or have a mode where it can run, in the foreground (i.e. no daemons)</li> </ol>"},{"location":"CI-CD/pre-commit-hook/","title":"Pre commit hook","text":""},{"location":"CI-CD/pre-commit-hook/#pre-commit","title":"`Pre commit","text":"<p>https://pre-commit.com/</p> <p>**Example</p> <pre><code>repos:  \n  - repo: local  \n    hooks:  \n      - id: run-docker-command  \n        name: Generate alerts, rules, tests  \n        language: script  \n        entry: ./src/run_docker.sh  \n        always_run: true  \n        files: .  \n  - repo: https://github.com/pre-commit/pre-commit-hooks  \n    rev: v2.4.0  \n    hooks:  \n      - id: trailing-whitespace  \n      - id: end-of-file-fixer  \n      - id: check-added-large-files  \n      - id: check-merge-conflict  \n      - id: mixed-line-ending  \n      - id: check-yaml  \n      - id: no-commit-to-branch  \n        name: branch needs format bugfix|feature/JIRA-123  \n        args: [\"--pattern\", '^(?!((bugfix|feature)\\/[A-Z]+-[0-9]+)$)']  \n  - repo: https://github.com/igorshubovych/markdownlint-cli  \n    rev: v0.39.0  \n    hooks:  \n      - id: markdownlint  \n        args: [\"--fix\"]  \n  - repo: local  \n    hooks:  \n      - id: Commit message check  \n        name: commit message needs format \"JIRA-123:\\sText message\"  \n        language: pygrep  \n        entry: '\\A([A-Z]+-[0-9]+:\\s\\S+)'  \n        args: [--multiline, --negate]  \n        stages: [commit-msg]  \n  - repo: local  \n    hooks:  \n      - id: check-new-files  \n        name: New untracked files found  \n        entry: bash -c 'if git status --porcelain teams common_templates | grep \"^??\"; then echo \"New untracked files found!\"; exit 1; fi'  \n        language: system  \n        always_run: true\n</code></pre> <p>Usage for any operations with resources in repo on pre commit stage</p>"},{"location":"CI-CD/Gitlab/Runners/","title":"Runners","text":""},{"location":"CI-CD/Gitlab/Runners/#add-runners","title":"Add runners","text":"<pre><code>sudo docker run -d --name gitlab-runner --restart always &gt;      -v /srv/gitlab-runner/config:/etc/gitlab-runner &gt;      -v /var/run/docker.sock:/var/run/docker.sock &gt;      gitlab/gitlab-runner:latest\n</code></pre> <p>**config.toml ```concurrent = 2 check_interval = 0</p> <p>[session_server]   session_timeout = 1800</p> <p>[[runners]]   name = \"docker-192-168-1-103\"   url = \"https://gitlab.com/\"   token = \"yours token\"   executor = \"docker\"   [runners.custom_build_dir]   [runners.cache]     [runners.cache.s3]     [runners.cache.gcs]     [runners.cache.azure]   [runners.docker]     tls_verify = false     image = \"docker:latest\"     privileged = true     disable_entrypoint_overwrite = false     oom_kill_disable = false     disable_cache = false     volumes = [\"/cache\",\"/var/run/docker.sock:/var/run/docker.sock\"]     shm_size = 0</p> <pre><code>**register runner\n</code></pre> <p>docker run --rm -it -v /srv/gitlab-runner/config:/etc/gitlab-runner gitlab/gitlab-runner register ```</p>"},{"location":"CI-CD/Gitlab/artifacts/","title":"Artifacts","text":"<pre><code>    artifacts:\n        untracked: true\n        paths:\n            - build/\n            - some/**/directories\n        exclude:\n            - build/dont-include-this-folder/\n            - some/**/directories/*.txt\n        expire: 1d \n</code></pre> <ul> <li># CI Artifacts: exclude paths</li> </ul>"},{"location":"Utilities/processes/lsof/","title":"Lsof","text":""},{"location":"Utilities/processes/lsof/#lsof","title":"<code>lsof</code>","text":"<p>List Open Files <code>lsof</code> Command Reference</p> <p>The <code>lsof</code> command is a powerful utility for listing open files and the processes that have them open. This tool is invaluable for system administrators when monitoring and troubleshooting a Linux system.</p> <p>Here are some essential <code>lsof</code> commands and their use cases:</p> <ul> <li>List Processes Using a Specific File or Directory</li> </ul> <p>To list all processes that are using a specific file or directory:</p> <p><code>bash   lsof /path/to/file</code></p> <ul> <li>Count the Number of Open Files by a Specific User</li> </ul> <p>To count the number of open files by the user <code>icefox</code>:</p> <p><code>bash   lsof -u icefox | wc -l</code></p> <ul> <li>Exclude a Specific User</li> </ul> <p>To exclude processes run by a specific user (e.g., <code>icefox</code>):</p> <p><code>bash   lsof -u^icefox | wc -l</code></p> <p>The <code>^</code> symbol is used to exclude the specified user.</p> <ul> <li>List All Unix Domain Socket Files</li> </ul> <p>To list all files related to Unix domain sockets:</p> <p><code>bash   lsof -U</code></p> <ul> <li>List Files Opened by Processes Starting with a Specific Command Name</li> </ul> <p>To list files opened by processes with command names that start with a specified string (e.g., <code>python</code>):</p> <p><code>bash   lsof -c python | head -15</code></p> <ul> <li> <p>Exclude Specific Commands: To list files opened by all <code>python</code> processes except those started with <code>python2.7</code>:</p> <p><code>bash lsof -c python -c^python2.7 | head -10</code></p> </li> <li> <p>List Files Opened in a Specific Directory (Non-recursive)</p> </li> </ul> <p>To list files and folders opened within a specific directory (but not in its subdirectories):</p> <p><code>bash   lsof +d /usr/bin | head -4</code></p> <ul> <li>List Files Opened by a Specific Process (PID)</li> </ul> <p>To list all files opened by a process with a specific PID:</p> <p><code>bash   lsof -p &lt;PID&gt;</code></p> <ul> <li>Find TCP Sockets Opened by a Specific Client</li> </ul> <p>To find information about TCP sockets opened by a specific client, you can filter the output using <code>grep</code>:</p> <p><code>bash   sudo lsof -Pni TCP | grep Mail</code></p> <ul> <li>List Files with Specific Internet Addresses</li> </ul> <p>The <code>-i</code> option lists information about files with internet addresses matching a specific pattern. If no address is specified, it will list all internet sockets and network files:</p> <p><code>bash   lsof -i</code></p> <p>You can also filter by protocol (e.g., <code>TCP</code>, <code>UDP</code>) and port numbers.</p>"},{"location":"Utilities/processes/lsof/#detailed-guide-on-the-lsof-command-in-linux","title":"Detailed Guide on the <code>lsof</code> Command in Linux","text":"<p>The <code>lsof</code> (List Open Files) command is an essential tool for system administrators and users who need to monitor or troubleshoot open files and the processes that have opened them. Since everything in Linux is treated as a file (including network connections, devices, and directories), <code>lsof</code> can provide a wealth of information about the system's current state.</p>"},{"location":"Utilities/processes/lsof/#basic-usage-of-lsof","title":"Basic Usage of <code>lsof</code>","text":"<p>The <code>lsof</code> command is highly versatile, with many options to filter and format the output. Below are some of the most common use cases.</p>"},{"location":"Utilities/processes/lsof/#1-list-all-open-files","title":"1. List All Open Files","text":"<p>To list all open files on the system:</p> <pre><code>sudo lsof\n</code></pre> <p>Since the output can be extensive, it's common to pipe it to <code>less</code> for easier viewing:</p> <pre><code>sudo lsof | less\n</code></pre>"},{"location":"Utilities/processes/lsof/#2-list-open-files-by-a-specific-user","title":"2. List Open Files by a Specific User","text":"<p>To list all open files by a specific user (e.g., <code>username</code>):</p> <pre><code>sudo lsof -u username\n</code></pre>"},{"location":"Utilities/processes/lsof/#3-list-open-files-by-a-specific-process","title":"3. List Open Files by a Specific Process","text":"<p>To list all open files associated with a specific process ID (PID):</p> <pre><code>sudo lsof -p &lt;PID&gt;\n</code></pre> <p>For example, to list open files by the process with PID 1234:</p> <pre><code>sudo lsof -p 1234\n</code></pre>"},{"location":"Utilities/processes/lsof/#4-list-open-files-for-a-specific-command","title":"4. List Open Files for a Specific Command","text":"<p>To list open files associated with a specific command (e.g., <code>sshd</code>):</p> <pre><code>sudo lsof -c sshd\n</code></pre> <p>This will list all files opened by processes that match the command name <code>sshd</code>.</p>"},{"location":"Utilities/processes/lsof/#5-list-open-files-in-a-specific-directory","title":"5. List Open Files in a Specific Directory","text":"<p>To list all open files within a specific directory (e.g., <code>/var/log</code>):</p> <pre><code>sudo lsof +D /var/log\n</code></pre> <p>The <code>+D</code> option lists all open files under the specified directory recursively.</p>"},{"location":"Utilities/processes/lsof/#6-list-open-network-connections","title":"6. List Open Network Connections","text":"<p>To list all open network connections:</p> <pre><code>sudo lsof -i\n</code></pre> <p>This command lists all open Internet, X.25, and UNIX domain socket files. It's particularly useful for troubleshooting network issues.</p>"},{"location":"Utilities/processes/lsof/#7-list-open-files-on-a-specific-port","title":"7. List Open Files on a Specific Port","text":"<p>To list open files associated with a specific network port (e.g., port 80):</p> <pre><code>sudo lsof -i :80\n</code></pre> <p>You can specify both TCP and UDP ports by appending <code>/tcp</code> or <code>/udp</code>, like this:</p> <pre><code>sudo lsof -iTCP:80\n</code></pre>"},{"location":"Utilities/processes/lsof/#8-list-open-files-by-protocol-tcpudp","title":"8. List Open Files by Protocol (TCP/UDP)","text":"<p>To filter open network files by protocol, you can use:</p> <pre><code>sudo lsof -i tcp\nsudo lsof -i udp\n</code></pre> <p>These commands will list all open TCP or UDP network connections, respectively.</p>"},{"location":"Utilities/processes/lsof/#9-find-files-opened-by-a-specific-network-address","title":"9. Find Files Opened by a Specific Network Address","text":"<p>To list files opened by a specific IP address:</p> <pre><code>sudo lsof -i @192.168.1.1\n</code></pre> <p>You can combine this with a port number as well:</p> <pre><code>sudo lsof -i @192.168.1.1:80\n</code></pre>"},{"location":"Utilities/processes/lsof/#10-list-open-files-by-file-descriptor-type","title":"10. List Open Files by File Descriptor Type","text":"<p>To filter by file descriptor type, such as regular files, directories, or sockets:</p> <pre><code>sudo lsof -d 1-3\n</code></pre> <p>This command lists open files with file descriptors in the range of 1 to 3.</p>"},{"location":"Utilities/processes/lsof/#understanding-the-output","title":"Understanding the Output","text":"<p>The output of <code>lsof</code> typically contains the following columns:</p> <ul> <li>COMMAND: The name of the command associated with the open file.</li> <li>PID: The Process ID of the command.</li> <li>USER: The user who owns the process.</li> <li>FD: The file descriptor, which shows how the file is being used (e.g., <code>cwd</code> for current working directory, <code>txt</code> for text files, <code>mem</code> for memory-mapped files, and numbers for regular file descriptors).</li> <li>TYPE: The type of node associated with the file (e.g., <code>REG</code> for regular file, <code>DIR</code> for directory, <code>CHR</code> for character special file).</li> <li>DEVICE: The device number.</li> <li>SIZE/OFF: The size or offset of the file.</li> <li>NODE: The inode number of the file.</li> <li>NAME: The name of the file or network address.</li> </ul>"},{"location":"Utilities/processes/lsof/#practical-use-cases","title":"Practical Use Cases","text":"<ul> <li>Identifying Files in Use Before Unmounting: Before unmounting a filesystem, use <code>lsof</code> to check if any files are still in use, which could prevent unmounting.</li> </ul> <p><code>bash   sudo lsof /mnt/mydisk</code></p> <ul> <li>Finding Open Files by Deleted Processes: To find files that are still open by processes even after they\u2019ve been deleted (useful for freeing up space):</li> </ul> <p><code>bash   sudo lsof | grep deleted</code></p> <ul> <li>Troubleshooting Network Services: If a service isn\u2019t starting because the port is already in use, you can identify which process is using the port:</li> </ul> <p><code>bash   sudo lsof -i :80</code></p> <ul> <li>Checking Which Files a Process is Using: This is useful for debugging or security purposes to see exactly what files a process is accessing.</li> </ul>"},{"location":"Utilities/processes/lsof/#conclusion","title":"Conclusion","text":"<p>The <code>lsof</code> command is a powerful utility for listing and managing open files on a Linux system. Whether you're troubleshooting system issues, monitoring network activity, or managing file systems, <code>lsof</code> provides invaluable insights into the current state of your system.</p> <p>For more advanced usage, refer to the <code>man lsof</code> page, which contains additional options and examples.</p>"},{"location":"Utilities/processes/ps/","title":"Ps","text":""},{"location":"Utilities/processes/ps/#ps","title":"<code>ps</code>","text":"<p>ps commands </p> <p>The <code>ps</code> command in Linux is a versatile tool used for monitoring and managing processes. It provides detailed information about running processes, including process IDs (PIDs), CPU and memory usage, and much more. This command is essential for system administrators and anyone needing to manage or troubleshoot processes on a Linux system.</p> <p>Here are some essential <code>ps</code> commands and their use cases:</p> <ul> <li>List All Processes</li> </ul> <p>To display a list of all processes running on the system:</p> <p><code>bash   ps aux</code></p> <p>This command provides a comprehensive view of all running processes along with their resource usage.</p> <ul> <li>View a Specific Process</li> </ul> <p>To view detailed information about a specific process by its PID (e.g., PID 123):</p> <p><code>bash   ps -up 123</code></p> <p>This command shows detailed information about the process with PID 123.</p> <ul> <li> <p>Sort Processes by Resource Usage</p> </li> <li> <p>By Memory Usage:</p> <p><code>bash ps aux --sort -rss</code></p> <p>Or using <code>sort</code>:</p> <p><code>bash ps aux | sort -nk 4</code></p> </li> <li> <p>By CPU Usage:</p> <p><code>bash ps aux --sort -%cpu</code></p> <p>Or using <code>sort</code>:</p> <p><code>bash ps aux | sort -nk 3</code></p> </li> </ul> <p>These commands allow you to quickly identify processes that are consuming the most memory or CPU resources.</p> <ul> <li>Display Process Hierarchy</li> </ul> <p>To display processes in a hierarchical tree format, showing their parent-child relationships:</p> <p><code>bash   ps auxf</code></p> <p>Or to view the process hierarchy for a specific user (e.g., <code>icefox</code>):</p> <p><code>bash   ps -f -U icefox</code></p> <ul> <li>List Processes Related to Your Terminal</li> </ul> <p>To list all processes related to your current terminal session:</p> <p><code>bash   ps -x</code></p>"},{"location":"Utilities/processes/ps/#process-state-codes","title":"Process State Codes","text":"<p>When you run <code>ps</code>, you might notice different state codes in the output, especially in the <code>STAT</code> or <code>S</code> columns. These codes represent the current state of the process:</p> <ul> <li>D: Uninterruptible sleep (usually I/O).</li> <li>R: Running or runnable (on run queue).</li> <li>S: Interruptible sleep (waiting for an event to complete).</li> <li>T: Stopped, either by a job control signal or because it is being traced.</li> <li>W: Paging (not valid since kernel 2.6.xx).</li> <li>X: Dead (should never be seen).</li> <li>Z: Defunct (\"zombie\") process, terminated but not reaped by its parent.</li> </ul>"},{"location":"Utilities/processes/ps/#additional-ps-commands-and-use-cases","title":"Additional <code>ps</code> Commands and Use Cases","text":"<ul> <li>List All Processes with Detailed Information</li> </ul> <p>To display a more detailed list of all running processes:</p> <p><code>bash   ps -ef</code></p> <p>This command provides extended information about each process, including parent PIDs (PPIDs) and start times.</p> <ul> <li>View a Specific User's Processes</li> </ul> <p>To view all processes owned by a specific user (e.g., <code>username</code>):</p> <p><code>bash   ps -u username</code></p> <p>This command lists only the processes started by the specified user.</p> <ul> <li>Monitor Processes Continuously</li> </ul> <p>Although <code>ps</code> does not inherently provide continuous monitoring like <code>top</code>, you can use <code>watch</code> to periodically run the <code>ps</code> command:</p> <p><code>bash   watch -n 1 'ps aux --sort=-%cpu | head'</code></p> <p>This command updates the list of top CPU-consuming processes every second.</p>"},{"location":"Utilities/processes/ps/#conclusion","title":"Conclusion","text":"<p>The <code>ps</code> command is a powerful and flexible tool for managing and monitoring processes on a Linux system. Whether you need to identify resource-hungry processes, view the process hierarchy, or simply check the state of running processes, <code>ps</code> offers a wide range of options to meet your needs. For more advanced usage, refer to the <code>man ps</code> page or explore additional resources like the linked ps commands guide.</p>"},{"location":"Virtualization/VirtualBox/","title":"VirtualBox","text":""},{"location":"Virtualization/VirtualBox/#ssh-access-with-nat-network","title":"SSH Access with NAT Network","text":"<p>When using a NAT network in a virtual machine, direct SSH access can be challenging because NAT hides internal IP addresses. To access the VM via SSH, you need to set up port forwarding in the NAT configuration.</p>"},{"location":"Virtualization/VirtualBox/#steps-to-configure-port-forwarding","title":"Steps to Configure Port Forwarding:","text":"<ol> <li>Open the Virtual Machine Settings:</li> <li>Open VirtualBox and select the desired virtual machine.</li> <li> <p>Go to the Settings section of the virtual machine.</p> </li> <li> <p>Network Configuration:</p> </li> <li>Navigate to the Network tab.</li> <li> <p>Ensure that the network is set to NAT mode.</p> </li> <li> <p>Adding Port Forwarding:</p> </li> <li>In the Advanced section, click on the Port Forwarding button.</li> <li>In the window that appears, add a new port forwarding rule.</li> <li>The settings for SSH should be as follows:<ul> <li>Protocol: TCP</li> <li>Host IP: leave blank or enter <code>127.0.0.1</code></li> <li>Host Port: choose a port on the host (e.g., <code>2222</code>)</li> <li>Guest IP: leave blank or enter the IP address inside the virtual machine</li> <li>Guest Port: usually <code>22</code> (the default SSH port)</li> </ul> </li> </ol> <p>![[forvardports657889.png]]</p>"},{"location":"balancers/envoy/","title":"Envoy","text":"<p>About envoy</p>"},{"location":"consul/KV/","title":"KV","text":"<p>**Put key to consul kv</p> <p>`consul kv put\u00a0 --datacenter da1 --http-addr=\"http://consul-relay.query.consul.preprod.crto.in:8500\"\u00a0 --token=\"some_token\" \"prometheus/vmalert/0/153\" \"test\"</p>"},{"location":"k8s/Kube/","title":"Kube","text":"<p>Debug busybox `kubectl run curl-my --image=radial/busyboxplus:curl -i --tty --rm</p> <p>Real-time logs</p> <p><code>kubectl logs -f -l app=duty-slack-app --max-log-requests 11 \u00a0 -n miniweb-testing</code>kubectl logs --since=6h -l app=reporter -n miniweb-b <code>kubectl edit roles.rbac.authorization.k8s.io leader-election-role</code>Kubetail oauth2-proxy -n Grafana-system `kubectl apply --force -f test_volume.yaml -n grafana-test</p> <p>Helm</p> <p><code>helm template tempo-vulture/chart -f tempo-vulture/chart/values.yaml &gt; file.yaml</code>helm template test helm -f cronjobs/.merged_values.yaml &gt; file.yaml <code>helm create mychart</code>helm template my-release mychart `helm get all ingress-nginx -n miniweb-system --revision 4 &gt; miniweb-test-ingress-nginx-4.yaml</p>"},{"location":"k8s/Operator%20SDK/","title":"Operator SDK","text":"<p>`operator-sdk init --domain crto.in --repo review.crto.in/incubator/slo-operatot</p> <p>`operator-sdk create api --group observability --version v1alpha1 --kind VMAlert --resource --controller</p> <p>problem m2, use go 1.21.7 https://github.com/operator-framework/operator-sdk/issues/6681</p>"},{"location":"topics/du%20how%20it%20work%3F/","title":"Du how it work?","text":"<p>The <code>du</code> command works by analyzing the file system and calculating the number of blocks occupied by files and directories on the disk. The process of how this command works can be broken down into several stages:</p>"},{"location":"topics/du%20how%20it%20work%3F/#stages-of-how-the-du-command-works","title":"Stages of how the <code>du</code> command works:","text":"<ol> <li>Searching for files and directories:</li> <li>When the <code>du</code> command is run without additional options, it starts from the specified directory (or the current directory if none is specified) and recursively traverses all files and subdirectories.</li> <li> <p>For each file and directory, it calculates how many disk blocks they occupy.</p> </li> <li> <p>Counting blocks:</p> </li> <li>In Linux, files on the disk are stored in blocks of fixed size, usually 4KB (4096 bytes), but this may vary depending on the file system.</li> <li>The <code>du</code> command calculates the number of these blocks for each file.</li> <li> <p>For directories, it sums up the size of all files and subdirectories they contain.</p> </li> <li> <p>Displaying size in blocks:</p> </li> <li> <p>By default, the <code>du</code> command displays the size of files and directories in blocks (usually 1 block = 1 kilobyte). However, using the <code>-h</code> flag allows you to output the size in a human-readable format (e.g., KB, MB, GB).</p> </li> <li> <p>Handling symbolic links:</p> </li> <li> <p>If a symbolic link is encountered, by default <code>du</code> only counts the size of the link itself (usually a few bytes) and not the size of the file it points to. This can be changed with flags (<code>-L</code> to count the target file's size).</p> </li> <li> <p>Ignoring duplicates via hard links:</p> </li> <li> <p>Hard links are multiple links to the same file on the disk. The <code>du</code> command by default counts the file's size only once, even if it has multiple hard links.</p> </li> <li> <p>Data aggregation:</p> </li> <li> <p>The command recursively processes all files and directories, summing their sizes, and then displays the total result for each directory. If the <code>-s</code> flag is specified, only the total size of the directory is shown without detailing its contents.</p> </li> <li> <p>Example of how it works at the system level:    Let's imagine you have a directory <code>/home/user</code> containing files. When you run <code>du /home/user</code>, the following happens:</p> </li> <li><code>du</code> opens the <code>/home/user</code> directory and retrieves a list of all files and subdirectories.</li> <li>For each file, the command accesses its metadata (using the <code>stat()</code> system call) to get information about the number of blocks occupied by this file.</li> <li>If the file is a directory, <code>du</code> recursively descends into it, summing the sizes of all files and subdirectories.</li> </ol>"},{"location":"topics/du%20how%20it%20work%3F/#interaction-with-the-file-system","title":"Interaction with the file system:","text":"<p>The <code>du</code> command uses system calls such as: - <code>opendir()</code> and <code>readdir()</code> to open and read the contents of directories. - <code>stat()</code> to retrieve file metadata, including information on the number of blocks, file owner, permissions, etc. - <code>lstat()</code> to work with symbolic links (to differentiate a symbolic link from a regular file).</p>"},{"location":"topics/du%20how%20it%20work%3F/#example-of-how-it-works","title":"Example of how it works:","text":"<p>If you run the <code>du</code> command on a large directory, the process will be as follows: 1. The command processes all files in the root directory. 2. It descends into each subdirectory and repeats the process. 3. For each file, it retrieves information on the number of blocks occupied by the file. 4. The sizes of all files and directories are summed to display the total directory size.</p> <p>Thus, the <code>du</code> command gives you an understanding of how disk space is being used, providing information for each directory or file based on the blocks allocated by the file system. </p>"},{"location":"utilities/CheatSheet/","title":"CheatSheet","text":""},{"location":"utilities/CheatSheet/#date","title":"date","text":"<p>Convert unixtime to human</p> <pre><code>date -r 1692541552253\n</code></pre>"},{"location":"utilities/CheatSheet/#watch","title":"watch","text":"<p>Periodically Execute a Command</p> <p>The <code>watch</code> command in Linux allows you to execute a command periodically, displaying the output in the terminal. It's particularly useful for monitoring system status and changes in real-time.</p> <ul> <li>Basic Usage</li> </ul> <p>To run a command every 2 seconds:</p> <p><code>bash   watch -n 2 \"some action\"</code></p> <ul> <li><code>-n 2</code>: Specifies the interval (in seconds) between command executions.</li> </ul>"},{"location":"utilities/CheatSheet/#ssh-and-scp-utilities","title":"SSH and SCP Utilities","text":""},{"location":"utilities/CheatSheet/#copying-ssh-key-to-a-remote-host","title":"Copying SSH Key to a Remote Host","text":"<p>To copy your SSH public key to a remote server for passwordless authentication:</p> <pre><code>ssh-copy-id -i ~/.ssh/id_rsa.pub YOUR_USER_NAME@IP_ADDRESS_OF_THE_SERVER\n</code></pre> <ul> <li>Batch Copying SSH Keys to Multiple Servers</li> </ul> <p>If you have a list of servers in a file and want to copy your SSH key to all of them:</p> <p><code>bash   #!/bin/bash   for ip in `cat /home/list_of_servers`; do       ssh-copy-id -i ~/.ssh/id_rsa.pub $ip   done</code></p> <p>This script reads a list of IP addresses from <code>/home/list_of_servers</code> and copies the SSH key to each server.</p>"},{"location":"utilities/CheatSheet/#accelerating-file-transfers-with-scp","title":"Accelerating File Transfers with SCP","text":"<p>To speed up file transfers with SCP using the Blowfish encryption algorithm:</p> <pre><code>scp -c blowfish root@host:/home/itsecforu/* /home/itsecforu\n</code></pre> <ul> <li>Copying Files to/from a Remote Host</li> </ul> <p>Basic usage of <code>scp</code> to copy files between hosts:</p> <p><code>bash   scp [other options] [source username@IP]:/[directory and file name] [destination username@IP]:/[destination directory]</code></p> <p>Example:</p> <p><code>bash   scp user@192.168.1.1:/home/user/file.txt /local/directory/</code></p> <ul> <li>Running Commands on Multiple Hosts</li> </ul> <p>To run a set of commands on multiple hosts listed in a file:</p> <p><code>bash   for HOST in $(cat hosts.txt); do ssh -f $HOST \"uptime; df -h\"; done</code></p> <p>This command executes <code>uptime</code> and <code>df -h</code> on each host listed in <code>hosts.txt</code>.</p> <ul> <li>Additional SSH Resources</li> <li>30 Questions and Answers about SSH</li> </ul>"},{"location":"utilities/CheatSheet/#managing-sudo-privileges","title":"Managing Sudo Privileges","text":""},{"location":"utilities/CheatSheet/#granting-a-user-sudo-access-without-a-password","title":"Granting a User Sudo Access Without a Password","text":"<p>To allow a user to execute <code>sudo</code> commands without being prompted for a password, add them to the <code>/etc/sudoers</code> file:</p> <ol> <li>Manually Edit <code>/etc/sudoers</code>:</li> </ol> <p>Add the following line:</p> <p><code>bash    username  ALL=(ALL) NOPASSWD:ALL</code></p> <ol> <li>Use a Command to Automate This:</li> </ol> <p>Alternatively, you can automate this process with:</p> <p><code>bash    echo \"username  ALL=(ALL) NOPASSWD:ALL\" | sudo tee /etc/sudoers.d/username</code></p> <p>This command adds the necessary line to a new file in <code>/etc/sudoers.d/</code>.</p> <ul> <li>Reference: How to Add User to Sudoers in Ubuntu</li> </ul>"},{"location":"utilities/CheatSheet/#openssl","title":"OpenSSL","text":"<p>Viewing SSL Certificate Data</p> <p>To view detailed information about an SSL certificate:</p> <pre><code>openssl x509 -in CERTPATH -text -noout\n</code></pre> <ul> <li><code>CERTPATH</code>: The path to the SSL certificate file.</li> </ul> <p>To initiate a TLS/SSL connection to a server and diagnose SSL issues use: </p> <pre><code>openssl s_client -connect myservername.domen.my:443 -servername myservername.domen.my\n</code></pre> <ul> <li><code>openssl s_client</code>: This tool connects to a remote server using SSL/TLS and helps in diagnosing SSL connections.</li> <li><code>-connect myservername.domen.my:443</code>: Specifies the server (<code>myservername.domen.my</code>) and port (<code>443</code>) to connect to. Port 443 is the default for HTTPS.</li> <li><code>-servername myservername.domen.my</code>: Sends the Server Name Indication (SNI), which allows the server to present the correct SSL certificate if it's hosting multiple domains.</li> </ul> <p>This command is useful for checking SSL certificate details, supported ciphers, and diagnosing connection issues.</p>"},{"location":"utilities/CheatSheet/#performance-testing","title":"Performance Testing","text":"<p>Apache Benchmarking</p> <p>To test the performance of a website using the Apache <code>ab</code> (Apache Benchmark) tool:</p> <ul> <li>Usage Example:</li> </ul> <p><code>bash   ab -n 1000 -c 10 http://example.com/</code></p> <ul> <li><code>-n 1000</code>: Number of requests to perform.</li> <li> <p><code>-c 10</code>: Number of multiple requests to make at a time.</p> </li> <li> <p>Resource: Apache Benchmarking Guide</p> </li> </ul>"},{"location":"utilities/Disk/","title":"Disk","text":""},{"location":"utilities/Disk/#comprehensive-guide-on-disk-analysis-io-and-mounting-in-linux","title":"Comprehensive Guide on Disk Analysis, I/O, and Mounting in Linux","text":"<p>Managing disk space, analyzing disk I/O performance, and properly mounting file systems are crucial tasks for system administrators. This guide covers essential Linux commands for these tasks, including <code>dd</code>, <code>du</code>, <code>df</code>, <code>iostat</code>, and <code>mount</code>.</p>"},{"location":"utilities/Disk/#disk-analysis","title":"Disk Analysis","text":""},{"location":"utilities/Disk/#1-viewing-disk-usage-with-du","title":"1. Viewing Disk Usage with <code>du</code>","text":"<p>The <code>du</code> (disk usage) command estimates the space used by files and directories.</p> <ul> <li>Basic Usage</li> </ul> <p>To display the disk usage of a directory and its subdirectories:</p> <p><code>bash   du -h /path/to/directory</code></p> <ul> <li> <p><code>-h</code>: Displays sizes in human-readable format (e.g., KB, MB, GB).</p> </li> <li> <p>Summarize Disk Usage</p> </li> </ul> <p>To display the total size of a directory:</p> <p><code>bash   du -sh /path/to/directory</code></p> <ul> <li> <p><code>-s</code>: Summarize, only shows the total size.</p> </li> <li> <p>Analyze Disk Usage with Sorting</p> </li> </ul> <p>To analyze disk usage and sort the results:</p> <p><code>bash   du -hsx /var/lib/docker/* | sort -rh | head -n 35</code></p> <ul> <li><code>-x</code>: Skip directories on different file systems.</li> <li><code>sort -rh</code>: Sort by size in reverse order.</li> <li><code>head -n 35</code>: Display the top 35 entries.</li> </ul> <p>Another example for <code>/home</code> directory:</p> <p><code>bash   du -hsx /home/* | sort -rh | head -n 35</code></p>"},{"location":"utilities/Disk/#2-checking-disk-space-with-df","title":"2. Checking Disk Space with <code>df</code>","text":"<p>The <code>df</code> (disk free) command reports file system disk space usage.</p> <ul> <li>Basic Disk Space Usage</li> </ul> <p>To display disk space usage for all mounted file systems:</p> <p><code>bash   df -h</code></p> <ul> <li> <p><code>-h</code>: Human-readable output.</p> </li> <li> <p>Check Specific File System</p> </li> </ul> <p>To check the disk space usage of a specific file system:</p> <p><code>bash   df -h /dev/sda1</code></p> <p>This will display information specific to the <code>/dev/sda1</code> file system.</p>"},{"location":"utilities/Disk/#3-disk-io-analysis-with-iostat","title":"3. Disk I/O Analysis with <code>iostat</code>","text":"<p>The <code>iostat</code> command is used to monitor system I/O device loading by observing the time the devices are active relative to their average transfer rates.</p> <ul> <li>Basic I/O Statistics</li> </ul> <p>To display I/O statistics:</p> <p><code>bash   iostat</code></p> <ul> <li>Detailed Report</li> </ul> <p>To get a detailed report with extended statistics:</p> <p><code>bash   iostat -x</code></p> <ul> <li> <p><code>-x</code>: Display extended statistics.</p> </li> <li> <p>Monitoring I/O Continuously</p> </li> </ul> <p>To monitor I/O performance every few seconds:</p> <p><code>bash   iostat 5</code></p> <p>This command will refresh the I/O statistics every 5 seconds.</p>"},{"location":"utilities/Disk/#disk-operations","title":"Disk Operations","text":""},{"location":"utilities/Disk/#1-copying-data-at-binary-level-with-dd","title":"1. Copying Data at Binary Level with <code>dd</code>","text":"<p>The <code>dd</code> command is used to copy and convert files at a binary level. It\u2019s commonly used for tasks like creating bootable USB drives, backing up disk partitions, and more.</p> <ul> <li>Basic Copying</li> </ul> <p>To copy data from one file or device to another:</p> <p><code>bash   dd if=/dev/sda of=/dev/sdb bs=64K conv=noerror,sync</code></p> <ul> <li><code>if</code>: Input file (source).</li> <li><code>of</code>: Output file (destination).</li> <li><code>bs</code>: Block size, here 64K is used.</li> <li> <p><code>conv=noerror,sync</code>: Continue on read errors and pad the output with zeros to maintain sync.</p> </li> <li> <p>Backup and Restore a Disk</p> </li> </ul> <p>To create an image of a disk:</p> <p><code>bash   dd if=/dev/sda of=/path/to/backup.img</code></p> <p>To restore from the image:</p> <p><code>bash   dd if=/path/to/backup.img of=/dev/sda</code></p> <ul> <li>Create a Bootable USB</li> </ul> <p>To create a bootable USB from an ISO file:</p> <p><code>bash   dd if=/path/to/iso of=/dev/sdb bs=4M status=progress</code></p> <ul> <li><code>status=progress</code>: Displays the progress of the operation.</li> </ul>"},{"location":"utilities/Disk/#mounting-file-systems","title":"Mounting File Systems","text":"<p>Mounting is the process of making a file system accessible at a certain point in the Linux directory tree.</p>"},{"location":"utilities/Disk/#1-basic-mounting","title":"1. Basic Mounting","text":"<p>To mount a disk or partition:</p> <pre><code>sudo mount /dev/sdb1 /mnt\n</code></pre> <ul> <li><code>/dev/sdb1</code>: The partition or disk to be mounted.</li> <li><code>/mnt</code>: The directory where the file system will be accessible.</li> </ul>"},{"location":"utilities/Disk/#2-unmounting","title":"2. Unmounting","text":"<p>To unmount a file system:</p> <pre><code>sudo umount /mnt\n</code></pre>"},{"location":"utilities/Disk/#3-persistent-mounting-adding-to-etcfstab","title":"3. Persistent Mounting (Adding to <code>/etc/fstab</code>)","text":"<p>To automatically mount a file system at boot, add an entry to <code>/etc/fstab</code>.</p> <p>Example entry for <code>/dev/sdb1</code>:</p> <pre><code>/dev/sdb1  /mnt  ext4  defaults  0  2\n</code></pre> <ul> <li><code>ext4</code>: The file system type.</li> <li><code>defaults</code>: Default mount options.</li> <li><code>0 2</code>: Dump (backup) and fsck (file system check) options.</li> </ul>"},{"location":"utilities/Disk/#4-viewing-mounted-file-systems","title":"4. Viewing Mounted File Systems","text":"<p>To view all currently mounted file systems:</p> <pre><code>mount | column -t\n</code></pre> <p>This command displays mounted file systems in a more readable format.</p>"},{"location":"utilities/Disk/#5-useful-resource-for-mounting-persistent-disks","title":"5. Useful Resource for Mounting Persistent Disks","text":"<p>For detailed instructions on mounting disks in cloud environments, you can refer to the following guide:</p> <ul> <li>How to Mount a Disk on Google Cloud</li> </ul>"},{"location":"utilities/Disk/#conclusion","title":"Conclusion","text":"<p>This guide provides a comprehensive overview of essential disk management commands in Linux. Understanding how to analyze disk usage, monitor I/O performance, and properly mount file systems is crucial for maintaining a healthy and efficient system.</p> <p>These tools (<code>dd</code>, <code>du</code>, <code>df</code>, <code>iostat</code>, <code>mount</code>) are powerful and versatile, allowing you to perform a wide range of tasks, from simple file system checks to advanced disk operations. Always refer to the <code>man</code> pages (e.g., <code>man dd</code>, <code>man du</code>, <code>man mount</code>) for more detailed information and additional options.</p>"},{"location":"utilities/Iptables/","title":"Iptables","text":""},{"location":"utilities/Iptables/#detailed-guide-on-iptables-and-routing-in-linux","title":"Detailed Guide on <code>iptables</code> and Routing in Linux","text":"<p><code>iptables</code> is a powerful command-line tool for configuring the Linux kernel's built-in firewall. It allows you to define rules for controlling network traffic. Alongside <code>iptables</code>, understanding routing is essential for managing how packets move through your network.</p>"},{"location":"utilities/Iptables/#iptables-basics","title":"<code>iptables</code> Basics","text":"<p><code>iptables</code> operates on a set of tables, each containing chains of rules that match packets and define actions. The most common tables are:</p> <ul> <li>Filter Table: The default table used for filtering packets (allowing or blocking traffic).</li> <li>NAT Table: Used for network address translation, which modifies packet source or destination addresses.</li> <li>Mangle Table: Used for specialized packet alterations.</li> <li>Raw Table: Used for configuring exemptions from connection tracking.</li> </ul> <p>Each table consists of several predefined chains:</p> <ul> <li>INPUT: Handles packets destined for the local system.</li> <li>OUTPUT: Handles packets originating from the local system.</li> <li>FORWARD: Handles packets being routed through the local system.</li> <li>PREROUTING: Alters packets before routing.</li> <li>POSTROUTING: Alters packets after routing.</li> </ul>"},{"location":"utilities/Iptables/#basic-commands","title":"Basic Commands","text":"<ul> <li>List Existing Rules</li> </ul> <p>To list all rules in the <code>filter</code> table:</p> <p><code>bash   sudo iptables -L</code></p> <p>For detailed output with line numbers:</p> <p><code>bash   sudo iptables -L -v -n --line-numbers</code></p> <ul> <li>Add a Rule</li> </ul> <p>To add a rule that allows incoming HTTP traffic (port 80):</p> <p><code>bash   sudo iptables -A INPUT -p tcp --dport 80 -j ACCEPT</code></p> <ul> <li><code>-A INPUT</code>: Appends a rule to the INPUT chain.</li> <li><code>-p tcp</code>: Specifies the protocol (TCP).</li> <li><code>--dport 80</code>: Specifies the destination port (80).</li> <li> <p><code>-j ACCEPT</code>: The action is to accept the packet.</p> </li> <li> <p>Delete a Rule</p> </li> </ul> <p>To delete the rule added above (using the rule number from the list command):</p> <p><code>bash   sudo iptables -D INPUT 1</code></p> <p>Here, <code>1</code> is the line number of the rule you want to delete.</p> <ul> <li>Block an IP Address</li> </ul> <p>To block all incoming traffic from a specific IP address:</p> <p><code>bash   sudo iptables -A INPUT -s 192.168.1.100 -j DROP</code></p> <ul> <li>Allow All Traffic on a Specific Interface</li> </ul> <p>To allow all traffic on a specific network interface (e.g., <code>eth0</code>):</p> <p><code>bash   sudo iptables -A INPUT -i eth0 -j ACCEPT</code></p>"},{"location":"utilities/Iptables/#nat-and-port-forwarding","title":"NAT and Port Forwarding","text":"<p>Network Address Translation (NAT) is often used to route packets between private networks and the internet.</p> <ul> <li>Masquerading</li> </ul> <p>This is used when the system is acting as a gateway for a private network. It translates the source address of outgoing packets to the public IP address of the gateway:</p> <p><code>bash   sudo iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE</code></p> <ul> <li><code>-t nat</code>: Specifies the NAT table.</li> <li><code>-o eth0</code>: Specifies the outgoing interface.</li> <li> <p><code>-j MASQUERADE</code>: Performs masquerading on the packet.</p> </li> <li> <p>Port Forwarding</p> </li> </ul> <p>To forward incoming traffic on port 8080 to an internal server on port 80:</p> <p><code>bash   sudo iptables -t nat -A PREROUTING -p tcp --dport 8080 -j DNAT --to-destination 192.168.1.10:80</code></p> <ul> <li> <p><code>-j DNAT</code>: Destination NAT, changing the destination IP/port.</p> </li> <li> <p>Saving Rules</p> </li> </ul> <p>To make sure your rules persist after a reboot, you can save them:</p> <ul> <li> <p>On Debian/Ubuntu:</p> <p><code>bash sudo iptables-save &gt; /etc/iptables/rules.v4</code></p> </li> <li> <p>On RedHat/CentOS:</p> <p><code>bash sudo service iptables save</code></p> </li> </ul>"},{"location":"utilities/Iptables/#advanced-features","title":"Advanced Features","text":"<ul> <li>Logging</li> </ul> <p>To log packets that match a certain rule:</p> <p><code>bash   sudo iptables -A INPUT -p tcp --dport 22 -j LOG --log-prefix \"SSH Connection: \"</code></p> <p>This logs packets with a custom prefix to <code>/var/log/messages</code> or a similar log file depending on your distribution.</p> <ul> <li>Rate Limiting</li> </ul> <p>To limit the number of incoming connections (e.g., to avoid brute-force attacks on SSH):</p> <p><code>bash   sudo iptables -A INPUT -p tcp --dport 22 -m state --state NEW -m recent --set   sudo iptables -A INPUT -p tcp --dport 22 -m state --state NEW -m recent --update --seconds 60 --hitcount 4 -j DROP</code></p>"},{"location":"utilities/Iptables/#routing-basics","title":"Routing Basics","text":"<p>Routing determines how packets are forwarded from one network to another. In Linux, routing decisions are made based on the routing table, which can be viewed and managed using the <code>ip</code> command.</p> <ul> <li>View the Routing Table</li> </ul> <p>To view the current routing table:</p> <p><code>bash   ip route show</code></p> <p>The output will show routes in the format: <code>destination via gateway dev interface</code>.</p> <ul> <li>Add a Static Route</li> </ul> <p>To add a route for a specific network:</p> <p><code>bash   sudo ip route add 192.168.2.0/24 via 192.168.1.1 dev eth0</code></p> <p>This command routes traffic for the <code>192.168.2.0/24</code> network via <code>192.168.1.1</code> on interface <code>eth0</code>.</p> <ul> <li>Delete a Route</li> </ul> <p>To delete a route:</p> <p><code>bash   sudo ip route del 192.168.2.0/24</code></p> <ul> <li>Set Default Gateway</li> </ul> <p>To set the default gateway (the route packets take if no other route matches):</p> <p><code>bash   sudo ip route add default via 192.168.1.1 dev eth0</code></p>"},{"location":"utilities/Iptables/#policy-based-routing","title":"Policy-Based Routing","text":"<p>Policy-based routing allows for more complex routing decisions based on policies other than just destination IP.</p> <ul> <li>Create a New Routing Table</li> </ul> <p>Edit <code>/etc/iproute2/rt_tables</code> and add a new table:</p> <p><code>200 my_custom_table</code></p> <ul> <li>Add Routes to the Custom Table</li> </ul> <p><code>bash   sudo ip route add 192.168.2.0/24 via 192.168.1.1 dev eth0 table my_custom_table</code></p> <ul> <li>Add a Routing Rule</li> </ul> <p><code>bash   sudo ip rule add from 192.168.1.100/32 table my_custom_table</code></p> <p>This command routes traffic from <code>192.168.1.100</code> using the custom table.</p>"},{"location":"utilities/Iptables/#conclusion","title":"Conclusion","text":"<p><code>iptables</code> and routing are essential components of network management in Linux. They allow you to control how traffic flows into, out of, and through your network. Whether you\u2019re managing a simple server or a complex network, understanding these tools will enable you to secure and optimize your network effectively.</p> <p>For more advanced usage, refer to the <code>man iptables</code>, <code>man ip</code>, and <code>man ip rule</code> pages.</p>"},{"location":"utilities/Memory/","title":"Memory","text":""},{"location":"utilities/Memory/#a-detailed-guide-to-monitoring-ram-in-linux","title":"A Detailed Guide to Monitoring RAM in Linux","text":"<p>Monitoring RAM usage is crucial for understanding system performance, diagnosing issues, and ensuring that applications have the resources they need. In Linux, several utilities allow you to monitor RAM usage, analyze memory allocation, and identify potential bottlenecks. This guide provides an overview of key tools for monitoring RAM, with detailed examples and explanations.</p>"},{"location":"utilities/Memory/#free","title":"<code>free</code>","text":"<p>Description: The <code>free</code> command provides a quick overview of the system's memory usage, including information on total, used, free, shared memory, and the buffer/cache.</p> <p>Basic Usage:</p> <pre><code>free -h\n</code></pre> <ul> <li><code>-h</code>: Outputs the memory usage in a human-readable format (e.g., KB, MB, GB).</li> </ul> <p>Detailed Usage:</p> <pre><code>free -m\n</code></pre> <ul> <li><code>-m</code>: Displays memory usage in megabytes.</li> </ul> <p>Understanding the Output:</p> <ul> <li>Total: The total amount of physical RAM available.</li> <li>Used: The amount of RAM currently in use.</li> <li>Free: The amount of RAM that is currently free.</li> <li>Shared: Memory used (mostly) by tmpfs (temporary file system).</li> <li>Buffers: Memory used by kernel buffers.</li> <li>Cache: Memory used by the page cache and slabs.</li> <li>Available: An estimate of how much memory is available for starting new applications without swapping.</li> </ul> <p>The buffer/cache section is crucial because it shows memory that is being used for buffering and caching by the operating system to improve performance. This memory is technically in use but can be quickly freed up for other purposes if needed, which is why the \"Available\" value is typically higher than the \"Free\" value.</p>"},{"location":"utilities/Memory/#top","title":"<code>top</code>","text":"<p>Description: <code>top</code> is an interactive command-line utility that displays a dynamic view of system processes, including memory and CPU usage.</p> <p>Basic Usage:</p> <pre><code>top\n</code></pre> <p>Understanding the Memory Section:</p> <p>At the top of the <code>top</code> display, you\u2019ll see memory usage statistics:</p> <ul> <li>KiB Mem: Total memory statistics.</li> <li>total: Total amount of RAM.</li> <li>used: RAM currently used by processes.</li> <li>free: RAM not in use by any processes.</li> <li>buff/cache: Combined memory used by the kernel buffers and the page cache.</li> <li>available: Approximate memory available for new processes.</li> </ul> <p>Sorting by Memory Usage:</p> <p>To sort processes by memory usage, press the <code>M</code> key while <code>top</code> is running.</p>"},{"location":"utilities/Memory/#htop","title":"<code>htop</code>","text":"<p>Description: <code>htop</code> is an enhanced version of <code>top</code>, providing a more user-friendly, color-coded, and interactive interface for monitoring processes and memory usage.</p> <p>Basic Usage:</p> <pre><code>htop\n</code></pre> <p>Features:</p> <ul> <li>Memory Graph: At the top of the interface, <code>htop</code> shows a bar graph for memory usage, with different colors representing different types of memory usage (e.g., buffers, cache, used).</li> <li>Interactive Sorting: You can easily sort processes by memory or CPU usage by clicking on the column headers or using function keys.</li> <li>Tree View: Shows processes in a hierarchical tree structure, making it easier to see parent-child relationships.</li> </ul> <p>Installation:</p> <p>If <code>htop</code> is not installed, you can install it using:</p> <pre><code>sudo apt install htop   # For Debian/Ubuntu\nsudo yum install htop   # For CentOS/RHEL\n</code></pre>"},{"location":"utilities/Memory/#vmstat","title":"<code>vmstat</code>","text":"<p>Description: <code>vmstat</code> reports virtual memory statistics, including processes, memory, paging, block I/O, traps, and CPU activity.</p> <p>Basic Usage:</p> <pre><code>vmstat 1 5\n</code></pre> <ul> <li><code>1</code>: The delay between updates in seconds.</li> <li><code>5</code>: The number of updates to display.</li> </ul> <p>Understanding the Memory Columns:</p> <ul> <li>swpd: Amount of virtual memory used.</li> <li>free: Amount of idle memory.</li> <li>buff: Amount of memory used as buffers.</li> <li>cache: Amount of memory used as cache.</li> <li>si/so: Swap in/out \u2014 the amount of memory swapped in or out to disk.</li> </ul> <p>The <code>buff</code> and <code>cache</code> fields are critical for understanding how Linux optimizes memory usage. Buffers are used for I/O operations, while the cache is used to store frequently accessed disk data to speed up access.</p>"},{"location":"utilities/Memory/#smem","title":"<code>smem</code>","text":"<p>Description: <code>smem</code> provides a more detailed view of memory usage by processes, accounting for both shared and private memory.</p> <p>Basic Usage:</p> <pre><code>smem -r\n</code></pre> <ul> <li><code>-r</code>: Sorts the output by resident memory (RSS).</li> </ul> <p>Detailed Usage:</p> <pre><code>smem -k -t -r -c \"pid user command swap rss\"\n</code></pre> <ul> <li><code>-k</code>: Display memory usage in kilobytes.</li> <li><code>-t</code>: Display a totals line.</li> <li><code>-c</code>: Specify columns to display.</li> </ul> <p>Understanding the Output:</p> <ul> <li>PID: Process ID.</li> <li>User: The user running the process.</li> <li>Command: The command used to start the process.</li> <li>Swap: Amount of swap used by the process.</li> <li>RSS: Resident Set Size \u2014 the portion of memory occupied by a process in RAM.</li> </ul> <p>Installation:</p> <p><code>smem</code> might need to be installed:</p> <pre><code>sudo apt install smem   # For Debian/Ubuntu\nsudo yum install smem   # For CentOS/RHEL\n</code></pre>"},{"location":"utilities/Memory/#ps","title":"<code>ps</code>","text":"<p>Description: <code>ps</code> is a versatile command used to list processes. It can be combined with other commands to sort and display memory usage.</p> <p>Basic Usage:</p> <pre><code>ps aux --sort=-%mem | head -n 10\n</code></pre> <ul> <li><code>--sort=-%mem</code>: Sorts processes by memory usage in descending order.</li> <li><code>head -n 10</code>: Displays the top 10 processes by memory usage.</li> </ul> <p>Understanding the Output:</p> <ul> <li>%MEM: Percentage of RAM used by the process.</li> <li>RSS: Resident Set Size \u2014 the actual physical memory used by the process.</li> </ul> <p>This command is useful for quickly identifying processes that consume the most memory.</p>"},{"location":"utilities/Memory/#glances","title":"<code>glances</code>","text":"<p>Description: <code>glances</code> is a comprehensive monitoring tool that provides a detailed overview of system performance, including memory usage.</p> <p>Basic Usage:</p> <pre><code>glances\n</code></pre> <p>Features:</p> <ul> <li>Memory Section: Shows detailed statistics on memory and swap usage.</li> <li>Real-Time Monitoring: Continuously updates system performance data.</li> <li>Alerts: Highlights issues like high memory usage with color codes.</li> </ul> <p>Installation:</p> <p>If <code>glances</code> is not installed, you can install it using:</p> <pre><code>sudo apt install glances   # For Debian/Ubuntu\nsudo yum install glances   # For CentOS/RHEL\n</code></pre>"},{"location":"utilities/Memory/#watch","title":"<code>watch</code>","text":"<p>Description: <code>watch</code> is not specifically a memory monitoring tool but can be used to periodically run any command to monitor memory usage over time.</p> <p>Basic Usage:</p> <pre><code>watch -n 5 free -m\n</code></pre> <ul> <li><code>-n 5</code>: Runs the <code>free -m</code> command every 5 seconds.</li> </ul> <p>This is useful for continuously monitoring memory usage with any of the above commands.</p>"},{"location":"utilities/Memory/#understanding-buffer-and-cache-in-linux-memory-management","title":"Understanding Buffer and Cache in Linux Memory Management","text":"<p>In Linux, memory management includes mechanisms like buffering and caching to optimize system performance:</p> <ul> <li> <p>Buffers: Buffers are used by the kernel to manage I/O operations. They store data temporarily while it is being transferred between devices or processes. This helps in managing bursty I/O operations efficiently.</p> </li> <li> <p>Cache: Cache memory stores copies of frequently accessed data from the disk, allowing the system to retrieve this data faster than if it had to read it from the disk every time. This improves overall system performance by reducing the need to access slower disk storage.</p> </li> </ul> <p>The memory used by buffers and cache is technically considered \"in use,\" but it can be quickly freed if needed by the system, making this memory \"available\" for applications when required.</p>"},{"location":"utilities/Memory/#conclusion","title":"Conclusion","text":"<p>Monitoring RAM in Linux is critical for ensuring optimal system performance. Tools like <code>free</code>, <code>top</code>, <code>htop</code>, <code>vmstat</code>, <code>smem</code>, <code>ps</code>, and <code>glances</code> provide various perspectives on memory usage, from high-level overviews to detailed per-process memory consumption. Understanding the role of buffers and cache in Linux\u2019s memory management system is also essential for interpreting the output of these tools correctly. By using these utilities effectively, you can gain deep insights into how your system is using its memory resources.</p>"},{"location":"utilities/Network/","title":"Network","text":"<p>Here's a mini-guide on essential networking commands in Linux:</p>"},{"location":"utilities/Network/#essential-networking-commands-in-linux","title":"Essential Networking Commands in Linux","text":"<p>This guide covers several key networking commands in Linux, useful for managing, troubleshooting, and monitoring networks.</p>"},{"location":"utilities/Network/#ifconfig","title":"<code>ifconfig</code>","text":"<p>The <code>ifconfig</code> command is used to configure, manage, and display network interface information in Linux. While it's considered deprecated in favor of the <code>ip</code> command, it's still widely used.</p> <ul> <li>Display network interfaces:</li> </ul> <p><code>bash   ifconfig</code></p> <ul> <li>Bring an interface up or down:</li> </ul> <p><code>bash   ifconfig eth0 up   ifconfig eth0 down</code></p> <ul> <li>Assign an IP address to an interface:</li> </ul> <p><code>bash   ifconfig eth0 192.168.1.100 netmask 255.255.255.0</code></p>"},{"location":"utilities/Network/#ip","title":"<code>ip</code>","text":"<p>The <code>ip</code> command is the modern replacement for <code>ifconfig</code>, offering more features and flexibility.</p> <ul> <li>Display all network interfaces and their IP addresses:</li> </ul> <p><code>bash   ip addr show</code></p> <ul> <li>Bring an interface up or down:</li> </ul> <p><code>bash   ip link set eth0 up   ip link set eth0 down</code></p> <ul> <li>Assign an IP address to an interface:</li> </ul> <p><code>bash   ip addr add 192.168.1.100/24 dev eth0</code></p> <ul> <li>Display routing table:</li> </ul> <p><code>bash   ip route show</code></p>"},{"location":"utilities/Network/#iptables","title":"<code>iptables</code>","text":"<p>The <code>iptables</code> command is used to configure the Linux kernel firewall, allowing you to define rules for packet filtering and NAT (Network Address Translation).</p> <ul> <li>View existing rules:</li> </ul> <p><code>bash   sudo iptables -L</code></p> <ul> <li>Allow incoming SSH connections:</li> </ul> <p><code>bash   sudo iptables -A INPUT -p tcp --dport 22 -j ACCEPT</code></p> <ul> <li>Block an IP address:</li> </ul> <p><code>bash   sudo iptables -A INPUT -s 192.168.1.100 -j DROP</code></p> <ul> <li>Save iptables rules (Debian/Ubuntu):</li> </ul> <p><code>bash   sudo iptables-save &gt; /etc/iptables/rules.v4</code></p>"},{"location":"utilities/Network/#nc-netcat","title":"<code>nc</code> (Netcat)","text":"<p><code>nc</code> is a versatile networking tool used for creating network connections, scanning ports, and transferring data.</p> <ul> <li>Scan for open ports:</li> </ul> <p><code>bash   nc -zv 192.168.1.1 1-1000</code></p> <ul> <li>Create a simple TCP server:</li> </ul> <p><code>bash   nc -l 1234</code></p> <ul> <li>Connect to a TCP server:</li> </ul> <p><code>bash   nc 192.168.1.1 1234</code></p> <ul> <li>Transfer a file:</li> </ul> <p>On the receiving side:</p> <p><code>bash   nc -l 1234 &gt; received_file</code></p> <p>On the sending side:</p> <p><code>bash   nc 192.168.1.1 1234 &lt; file_to_send</code></p>"},{"location":"utilities/Network/#nmap","title":"<code>nmap</code>","text":"<p><code>nmap</code> is a powerful network scanning tool used for discovering hosts and services on a network.</p> <ul> <li>Basic scan to detect open ports:</li> </ul> <p><code>bash   nmap 192.168.1.1</code></p> <ul> <li>Scan a range of IP addresses:</li> </ul> <p><code>bash   nmap 192.168.1.1-255</code></p> <ul> <li>Scan using a specific port range:</li> </ul> <p><code>bash   nmap -p 1-1000 192.168.1.1</code></p> <ul> <li>Detect the operating system of a remote host:</li> </ul> <p><code>bash   sudo nmap -O 192.168.1.1</code></p>"},{"location":"utilities/Network/#tcpdump","title":"<code>tcpdump</code>","text":"<p><code>tcpdump</code> is a command-line packet analyzer used for capturing and analyzing network traffic.</p> <ul> <li>Capture all packets on a specific interface:</li> </ul> <p><code>bash   sudo tcpdump -i eth0</code></p> <ul> <li>Capture packets from a specific host:</li> </ul> <p><code>bash   sudo tcpdump -i eth0 host 192.168.1.1</code></p> <ul> <li>Capture only TCP packets:</li> </ul> <p><code>bash   sudo tcpdump -i eth0 tcp</code></p> <ul> <li>Save captured packets to a file:</li> </ul> <p><code>bash   sudo tcpdump -i eth0 -w capture.pcap</code></p>"},{"location":"utilities/Network/#ping","title":"<code>ping</code>","text":"<p>The <code>ping</code> command is used to test the reachability of a host on an IP network and to measure the round-trip time for messages sent from the source to the destination.</p> <ul> <li>Ping a host:</li> </ul> <p><code>bash   ping 192.168.1.1</code></p> <ul> <li>Ping a host with a specific count of packets:</li> </ul> <p><code>bash   ping -c 4 192.168.1.1</code></p>"},{"location":"utilities/Network/#traceroute","title":"<code>traceroute</code>","text":"<p><code>traceroute</code> displays the route that packets take to reach a network host.</p> <ul> <li>Trace the route to a host:</li> </ul> <p><code>bash   traceroute 192.168.1.1</code></p>"},{"location":"utilities/Network/#netstat","title":"<code>netstat</code>","text":"<p><code>netstat</code> is a command-line tool that provides information about network connections, routing tables, interface statistics, masquerade connections, and multicast memberships.</p> <ul> <li>Display all active connections:</li> </ul> <p><code>bash   netstat -a</code></p> <ul> <li>Display listening ports:</li> </ul> <p><code>bash   netstat -l</code></p> <ul> <li>Display network interface statistics:</li> </ul> <p><code>bash   netstat -i</code></p>"},{"location":"utilities/Network/#ss","title":"<code>ss</code>","text":"<p><code>ss</code> is a utility to investigate sockets. It can display more detailed information than <code>netstat</code> and is considered its replacement.</p> <ul> <li>Display all TCP connections:</li> </ul> <p><code>bash   ss -t</code></p> <ul> <li>Display all UDP connections:</li> </ul> <p><code>bash   ss -u</code></p> <ul> <li>Display listening ports:</li> </ul> <p><code>bash   ss -l</code></p>"},{"location":"utilities/Text%20files/","title":"Text files","text":""},{"location":"utilities/Text%20files/#grep","title":"<code>grep</code>","text":"<pre><code>cat syslog | grep -E \u20182005/07/19 09:00./ivr/common\u2019 | grep -v \u2018try_transfer' &gt; sample_nauivrd.log.\n</code></pre> <p>grep operators</p>"},{"location":"utilities/Text%20files/#sed","title":"<code>sed</code>","text":""},{"location":"utilities/Text%20files/#splitting-a-file-into-parts","title":"Splitting a File into Parts","text":"<p>To split a file into parts where <code>4646</code> is the starting line and <code>9999</code> is the ending line:</p> <pre><code>sed -n 4646,9999p old.file &gt; new.file\n</code></pre>"},{"location":"utilities/Text%20files/#display-lines-5-10","title":"Display Lines 5-10","text":"<p>To display lines 5 through 10:</p> <pre><code>sed -n '5,10p' /etc/group\n</code></pre>"},{"location":"utilities/Text%20files/#display-all-lines-except-5-10","title":"Display All Lines Except 5-10","text":"<p>To display all lines except for lines 5 through 10:</p> <pre><code>sed -n '5,10d' /etc/group\n</code></pre>"},{"location":"utilities/Text%20files/#substitution-command","title":"Substitution Command","text":"<p>The command <code>s/pattern1/pattern2/</code> is used for substitution. The letter \"s\" stands for \"substitute.\"</p>"},{"location":"utilities/Text%20files/#extracting-a-portion-of-a-file","title":"Extracting a Portion of a File","text":"<p>To extract a portion of a file from byte 10001 to 20000:</p> <pre><code>cat blabla.dump | cut -b 10001-20000 &gt; mumu.dump\n</code></pre> <p>Here's a mini-guide on using the <code>tail</code> command in Linux:</p>"},{"location":"utilities/Text%20files/#tail","title":"<code>tail</code>","text":"<p>The <code>tail</code> command is used to display the last part of a file or stream in Linux. By default, it shows the last 10 lines of a file, but you can customize this behavior with various options.</p>"},{"location":"utilities/Text%20files/#basic-usage","title":"Basic Usage","text":"<p>To display the last 10 lines of a file:</p> <pre><code>tail filename\n</code></pre>"},{"location":"utilities/Text%20files/#display-a-specific-number-of-lines","title":"Display a Specific Number of Lines","text":"<p>To display a specific number of lines from the end of a file, use the <code>-n</code> option followed by the number of lines:</p> <pre><code>tail -n 20 filename\n</code></pre> <p>This will display the last 20 lines of the file.</p>"},{"location":"utilities/Text%20files/#display-the-last-n-bytes","title":"Display the Last N Bytes","text":"<p>If you want to display the last N bytes instead of lines, use the <code>-c</code> option:</p> <pre><code>tail -c 50 filename\n</code></pre> <p>This will display the last 50 bytes of the file.</p>"},{"location":"utilities/Text%20files/#follow-a-file-in-real-time","title":"Follow a File in Real-Time","text":"<p>One of the most powerful features of <code>tail</code> is the ability to follow a file in real-time as new lines are added. This is particularly useful for monitoring log files:</p> <pre><code>tail -f filename\n</code></pre> <p>This command will display the last few lines of the file and continue to output new lines as they are written to the file.</p> <p>You can combine <code>-f</code> with <code>-n</code> to start from a specific number of lines and continue following:</p> <pre><code>tail -n 50 -f filename\n</code></pre>"},{"location":"utilities/Text%20files/#stop-following-after-a-certain-period","title":"Stop Following After a Certain Period","text":"<p>If you want to follow a file for a limited amount of time, use the <code>--pid</code> option along with a process ID, or <code>--max-unchanged-stats</code> to stop after a certain period of inactivity:</p> <pre><code>tail -f filename --pid=1234\n</code></pre> <p>Or:</p> <pre><code>tail -f filename --max-unchanged-stats=5s\n</code></pre>"},{"location":"utilities/Text%20files/#example-monitoring-system-logs","title":"Example: Monitoring System Logs","text":"<p>A common use case for <code>tail</code> is monitoring system logs:</p> <pre><code>tail -f /var/log/syslog\n</code></pre> <p>This command will display the latest system log entries as they are added to the file.</p> <p>Here are mini-guides for the <code>tar</code> and <code>tr</code> commands in Linux:</p>"},{"location":"utilities/Text%20files/#tar-command-in-linux","title":"<code>tar</code> Command in Linux","text":"<p>The <code>tar</code> command is used to create, extract, and manage archive files in Linux. It is commonly used to compress and package multiple files into a single file for easier distribution or backup.</p>"},{"location":"utilities/Text%20files/#basic-usage_1","title":"Basic Usage","text":"<p>To create a <code>tar</code> archive:</p> <pre><code>tar -cvf archive_name.tar directory_or_file\n</code></pre> <ul> <li><code>-c</code> : Create a new archive.</li> <li><code>-v</code> : Verbose mode, shows progress in the terminal.</li> <li><code>-f</code> : Specifies the filename of the archive.</li> </ul>"},{"location":"utilities/Text%20files/#compressing-an-archive-with-gzip","title":"Compressing an Archive with <code>gzip</code>","text":"<p>To compress the archive using <code>gzip</code>, use the <code>-z</code> option:</p> <pre><code>tar -czvf archive_name.tar.gz directory_or_file\n</code></pre> <ul> <li><code>-z</code> : Compress the archive using <code>gzip</code>.</li> </ul>"},{"location":"utilities/Text%20files/#extracting-an-archive","title":"Extracting an Archive","text":"<p>To extract a <code>tar</code> archive:</p> <pre><code>tar -xvf archive_name.tar\n</code></pre> <ul> <li><code>-x</code> : Extract files from an archive.</li> </ul> <p>For compressed archives:</p> <pre><code>tar -xzvf archive_name.tar.gz\n</code></pre>"},{"location":"utilities/Text%20files/#extracting-a-specific-file","title":"Extracting a Specific File","text":"<p>To extract a specific file from a <code>tar</code> archive:</p> <pre><code>tar -xvf archive_name.tar file_to_extract\n</code></pre>"},{"location":"utilities/Text%20files/#list-contents-of-an-archive","title":"List Contents of an Archive","text":"<p>To list the contents of a <code>tar</code> archive without extracting:</p> <pre><code>tar -tvf archive_name.tar\n</code></pre> <ul> <li><code>-t</code> : List the contents of the archive.</li> </ul>"},{"location":"utilities/Text%20files/#example-creating-and-extracting-an-archive","title":"Example: Creating and Extracting an Archive","text":"<p>Create a compressed archive:</p> <pre><code>tar -czvf backup.tar.gz /path/to/directory\n</code></pre> <p>Extract the compressed archive:</p> <pre><code>tar -xzvf backup.tar.gz\n</code></pre>"},{"location":"utilities/Text%20files/#tr-command-in-linux","title":"<code>tr</code> Command in Linux","text":"<p>The <code>tr</code> command is used to translate or delete characters from the input provided to it. It reads from standard input and writes to standard output, making it useful for various text processing tasks.</p>"},{"location":"utilities/Text%20files/#basic-usage_2","title":"Basic Usage","text":"<p>To translate characters, specify the characters to replace and their replacements:</p> <pre><code>echo \"hello world\" | tr 'a-z' 'A-Z'\n</code></pre> <p>This command converts all lowercase letters to uppercase:</p> <p>Output:</p> <pre><code>HELLO WORLD\n</code></pre>"},{"location":"utilities/Text%20files/#delete-specific-characters","title":"Delete Specific Characters","text":"<p>To delete specific characters, use the <code>-d</code> option:</p> <pre><code>echo \"hello 123 world\" | tr -d '0-9'\n</code></pre> <p>This will remove all digits from the text:</p> <p>Output:</p> <pre><code>hello  world\n</code></pre>"},{"location":"utilities/Text%20files/#replace-multiple-spaces-with-a-single-space","title":"Replace Multiple Spaces with a Single Space","text":"<p>To replace multiple spaces with a single space:</p> <pre><code>echo \"hello     world\" | tr -s ' '\n</code></pre> <ul> <li><code>-s</code> : Squeeze, which replaces sequences of a character with a single instance.</li> </ul> <p>Output:</p> <pre><code>hello world\n</code></pre>"},{"location":"utilities/Text%20files/#example-translating-and-deleting-characters","title":"Example: Translating and Deleting Characters","text":"<p>Translate spaces to newlines:</p> <pre><code>echo \"apple orange banana\" | tr ' ' '\\n'\n</code></pre> <p>Delete all vowels from the input:</p> <pre><code>echo \"hello world\" | tr -d 'aeiou'\n</code></pre> <p>Output:</p> <pre><code>hll wrld\n</code></pre>"},{"location":"utilities/processes/sar/","title":"Sar","text":""},{"location":"utilities/processes/sar/#sar","title":"<code>sar</code>","text":"<p>System Activity Reporter <code>sar</code></p> <p>The <code>sar</code> (System Activity Reporter) command in Linux is a powerful tool for monitoring system performance. It collects, reports, and saves system activity information, making it a valuable utility for analyzing the performance of CPU, memory, disk, and network activities over time.</p>"},{"location":"utilities/processes/sar/#basic-usage-of-sar","title":"Basic Usage of <code>sar</code>","text":"<p>Here are some essential <code>sar</code> commands and their use cases:</p> <ul> <li>Basic CPU Usage Monitoring</li> </ul> <p>To monitor CPU usage at 1-second intervals for 5 iterations:</p> <p><code>bash   sar 1 5</code></p> <ul> <li>The first argument (<code>1</code>) specifies the interval in seconds between each report.</li> <li>The second argument (<code>5</code>) specifies the number of reports to generate.</li> </ul> <p>This command outputs CPU usage statistics such as user time, system time, and idle time at each interval.</p> <ul> <li>Monitoring Disk Activity</li> </ul> <p>To monitor disk activity at 1-second intervals for 5 iterations:</p> <p><code>bash   sar -d 1 5</code></p> <ul> <li><code>-d</code>: Reports disk activity statistics, including read/write operations per second and average request size.</li> </ul> <p>This command provides a snapshot of disk performance, helping identify I/O bottlenecks or issues with disk utilization.</p>"},{"location":"utilities/processes/sar/#understanding-sar-output","title":"Understanding <code>sar</code> Output","text":"<p>The output of <code>sar</code> varies depending on the options used. Here's a brief overview of common metrics:</p> <ul> <li>CPU Metrics:</li> <li><code>%user</code>: Percentage of CPU utilization that occurred while executing user-level code.</li> <li><code>%system</code>: Percentage of CPU utilization that occurred while executing system-level code.</li> <li> <p><code>%idle</code>: Percentage of CPU time spent idle.</p> </li> <li> <p>Disk Metrics:</p> </li> <li><code>tps</code>: Transfers per second (I/O operations).</li> <li><code>rd_sec/s</code>: Number of sectors read per second.</li> <li><code>wr_sec/s</code>: Number of sectors written per second.</li> <li><code>avgrq-sz</code>: Average size (in sectors) of the requests that were issued to the device.</li> </ul>"},{"location":"utilities/processes/sar/#practical-use-cases","title":"Practical Use Cases","text":"<ul> <li>Real-Time CPU Monitoring: Use <code>sar</code> to get a quick overview of CPU usage in real-time, which can help identify processes that are overutilizing the CPU.</li> </ul> <p><code>bash   sar 1 5</code></p> <ul> <li>Analyzing Disk I/O Performance: If your system is experiencing slow disk performance, use <code>sar -d</code> to monitor disk I/O and identify potential bottlenecks.</li> </ul> <p><code>bash   sar -d 1 5</code></p> <ul> <li>Historical Performance Analysis: <code>sar</code> can be configured to collect system performance data over time, which can then be analyzed to identify trends or issues that develop gradually.</li> </ul> <p>For example, to view historical CPU usage from the sar logs:</p> <p><code>bash   sar -f /var/log/sa/sa10</code></p> <p>Here, <code>/var/log/sa/sa10</code> refers to a sar log file for a specific day.</p>"},{"location":"utilities/processes/sar/#conclusion","title":"Conclusion","text":"<p>The <code>sar</code> command is a versatile and powerful tool for system performance monitoring in Linux. Whether you're interested in real-time performance data or historical analysis, <code>sar</code> provides detailed insights into CPU, disk, and other system activities. For more in-depth usage and advanced options, refer to the <code>man sar</code> page or explore additional resources like the linked sar guide.</p>"},{"location":"utilities/processes/ss/","title":"Ss","text":""},{"location":"utilities/processes/ss/#detailed-guide-on-ss","title":"Detailed Guide on <code>ss</code>","text":"<p>The <code>ss</code> command in Linux is a powerful utility for investigating sockets. It can display detailed information about network connections, listening ports, and much more. It is often considered a more modern and feature-rich alternative to the older <code>netstat</code> command.</p>"},{"location":"utilities/processes/ss/#basic-usage-of-ss","title":"Basic Usage of <code>ss</code>","text":"<p>The <code>ss</code> command provides a comprehensive set of options to display various types of socket information. Here are some of the most commonly used options:</p> <ul> <li><code>-t</code>: Display only TCP sockets.</li> <li><code>-u</code>: Display only UDP sockets.</li> <li><code>-l</code>: Show only listening sockets.</li> <li><code>-a</code>: Show both listening and non-listening (active) sockets.</li> <li><code>-p</code>: Display the process using the socket.</li> <li><code>-n</code>: Do not resolve service names (use numeric values).</li> <li><code>-r</code>: Resolve numeric addresses to hostnames.</li> <li><code>-s</code>: Display summary statistics.</li> <li><code>-4</code>: Display only IPv4 sockets.</li> <li><code>-6</code>: Display only IPv6 sockets.</li> </ul>"},{"location":"utilities/processes/ss/#examples","title":"Examples","text":""},{"location":"utilities/processes/ss/#1-list-all-tcp-connections","title":"1. List All TCP Connections","text":"<p>To list all TCP connections:</p> <pre><code>ss -t\n</code></pre> <p>This command will show all active TCP connections on the system.</p>"},{"location":"utilities/processes/ss/#2-list-all-listening-ports-tcp","title":"2. List All Listening Ports (TCP)","text":"<p>To display all listening TCP ports:</p> <pre><code>ss -tl\n</code></pre> <p>This command lists only the listening TCP ports. This is useful to see which services are waiting for incoming connections.</p>"},{"location":"utilities/processes/ss/#3-show-detailed-information-with-process-names","title":"3. Show Detailed Information with Process Names","text":"<p>To display detailed information, including process names, for TCP sockets:</p> <pre><code>sudo ss -tpla\n</code></pre> <ul> <li><code>-p</code>: Includes the process using the socket.</li> <li><code>-l</code>: Includes only listening sockets.</li> <li><code>-a</code>: Shows all sockets (listening and non-listening).</li> </ul>"},{"location":"utilities/processes/ss/#4-filter-by-process-name","title":"4. Filter by Process Name","text":"<p>To filter the results by a specific process, such as MySQL:</p> <pre><code>sudo ss -tap | grep mysql\n</code></pre> <p>This command will display only the TCP sockets associated with the MySQL service.</p> <p>Alternatively, if you want to see all sockets (listening and established) related to MySQL:</p> <pre><code>sudo ss -tlap | grep mysql\n</code></pre> <ul> <li><code>-t</code>: Show TCP sockets.</li> <li><code>-l</code>: Include listening sockets.</li> <li><code>-a</code>: Show all sockets.</li> <li><code>-p</code>: Include process information.</li> </ul>"},{"location":"utilities/processes/ss/#5-show-tcp-connections-with-hostname-resolution","title":"5. Show TCP Connections with Hostname Resolution","text":"<p>To display TCP connections and resolve IP addresses to hostnames:</p> <pre><code>sudo ss -tr\n</code></pre> <ul> <li><code>-r</code>: Resolves IP addresses to hostnames.</li> </ul>"},{"location":"utilities/processes/ss/#6-list-all-udp-connections","title":"6. List All UDP Connections","text":"<p>To display all active UDP connections:</p> <pre><code>ss -u\n</code></pre> <p>This will list all UDP connections without showing listening sockets by default.</p>"},{"location":"utilities/processes/ss/#7-show-ipv4-only-or-ipv6-only-sockets","title":"7. Show IPv4 Only or IPv6 Only Sockets","text":"<p>To list only IPv4 sockets:</p> <pre><code>ss -4\n</code></pre> <p>To list only IPv6 sockets:</p> <pre><code>ss -6\n</code></pre>"},{"location":"utilities/processes/ss/#8-display-summary-statistics","title":"8. Display Summary Statistics","text":"<p>To display summary statistics of the socket usage:</p> <pre><code>ss -s\n</code></pre> <p>This provides an overview of the current socket state, including the number of established, closed, orphaned, and waiting connections.</p>"},{"location":"utilities/processes/ss/#understanding-the-output","title":"Understanding the Output","text":"<p>When you run a basic <code>ss</code> command, the output columns include:</p> <ul> <li>Netid: The type of socket (e.g., <code>tcp</code>, <code>udp</code>).</li> <li>State: The current state of the connection (e.g., <code>ESTAB</code> for established, <code>LISTEN</code> for listening).</li> <li>Recv-Q: The number of bytes not copied by the user program connected to this socket.</li> <li>Send-Q: The number of bytes not acknowledged by the remote host.</li> <li>Local Address:Port: The local IP address and port number.</li> <li>Peer Address:Port: The remote IP address and port number.</li> <li>Process: The process name and PID associated with the socket (shown with <code>-p</code>).</li> </ul>"},{"location":"utilities/processes/ss/#practical-use-cases","title":"Practical Use Cases","text":"<ul> <li>Monitoring open ports: Use <code>ss -tl</code> to see which ports are open and listening for connections. This is useful for security audits.</li> <li>Diagnosing network issues: Use <code>ss -t</code> to see active TCP connections, which can help diagnose connectivity problems.</li> <li>Identifying resource hogs: Use <code>ss -tpla</code> to find processes that are consuming network resources.</li> </ul>"},{"location":"utilities/processes/ss/#conclusion","title":"Conclusion","text":"<p>The <code>ss</code> command is a powerful tool for network troubleshooting and monitoring. It provides detailed information about all sockets on your system, including established connections, listening sockets, and the processes associated with them. Whether you're a system administrator or a network engineer, <code>ss</code> is an indispensable tool for managing and securing your Linux environment.</p> <p>For further details, consult the <code>man ss</code> page or explore additional options and filters to tailor the output to your specific needs.</p>"},{"location":"utilities/processes/strace/","title":"Strace","text":""},{"location":"utilities/processes/strace/#strace","title":"<code>strace</code>","text":"<p>System Call Tracer <code>strace</code></p> <p>The <code>strace</code> command in Linux is a powerful diagnostic and debugging tool used to monitor and analyze system calls made by a process and the signals it receives. This tool is particularly useful for understanding how a program interacts with the operating system, and for troubleshooting issues related to system calls.</p> <p>Here are some essential <code>strace</code> commands and their use cases:</p> <ul> <li>Basic Usage</li> </ul> <p>To trace the system calls made by a simple command (e.g., <code>uname</code>):</p> <p><code>bash   strace uname</code></p> <p>This command outputs a list of all system calls made by the <code>uname</code> command, along with their return values.</p> <ul> <li>Trace a Command with Detailed Output</li> </ul> <p>To run a command with <code>strace</code> and see detailed output, including following child processes (<code>-f</code>) and setting a string limit for output (<code>-s</code>):</p> <p><code>bash   strace -s 1024 -f bash -c \"ls | grep hello\"</code></p> <ul> <li><code>-s 1024</code>: Sets the maximum string size to print in the trace to 1024 characters.</li> <li><code>-f</code>: Follows child processes created by <code>fork()</code>.</li> </ul> <p>This command traces the execution of the <code>ls | grep hello</code> pipeline within a <code>bash</code> shell, providing a detailed view of system calls, including those made by any child processes.</p> <ul> <li>Attach to a Running Process</li> </ul> <p>To attach <code>strace</code> to an already running process by its PID (e.g., PID 123):</p> <p><code>bash   sudo strace -p 123</code></p> <p>This allows you to observe the system calls made by a process that is already running. It's useful for diagnosing issues in long-running processes without restarting them.</p>"},{"location":"utilities/processes/strace/#understanding-strace-output","title":"Understanding <code>strace</code> Output","text":"<p>The output of <code>strace</code> consists of lines that represent individual system calls. Each line typically includes:</p> <ul> <li>System Call Name: The name of the system call being made (e.g., <code>open</code>, <code>read</code>, <code>write</code>).</li> <li>Arguments: The arguments passed to the system call.</li> <li>Return Value: The result of the system call (e.g., a file descriptor, number of bytes read/written, or an error code).</li> </ul> <p>For example, an output line might look like this:</p> <pre><code>open(\"/etc/hosts\", O_RDONLY) = 3\n</code></pre> <p>This line indicates that the <code>open</code> system call was used to open the file <code>/etc/hosts</code> in read-only mode, and the call returned the file descriptor <code>3</code>.</p>"},{"location":"utilities/processes/strace/#practical-use-cases","title":"Practical Use Cases","text":"<ul> <li>Debugging Program Execution: <code>strace</code> is often used to debug issues where a program is not behaving as expected. By observing the system calls, you can identify where a program might be failing or getting stuck.</li> </ul> <p><code>bash   strace -o output.txt ./my_program</code></p> <p>This command runs <code>my_program</code> and saves the <code>strace</code> output to <code>output.txt</code> for later analysis.</p> <ul> <li>Analyzing File Access: If you need to see which files a program is trying to access, <code>strace</code> can help identify any missing files or permission issues.</li> </ul> <p><code>bash   strace -e trace=file ./my_program</code></p> <p>The <code>-e trace=file</code> option limits the trace to file-related system calls.</p> <ul> <li>Monitoring Network Activity: You can use <code>strace</code> to monitor network-related system calls, such as <code>connect</code>, <code>sendto</code>, and <code>recvfrom</code>.</li> </ul> <p><code>bash   strace -e trace=network ./network_program</code></p> <p>This is useful for debugging network connectivity issues.</p> <ul> <li>Understanding Program Behavior: Sometimes, <code>strace</code> is used simply to understand how a program interacts with the operating system, which can be useful for learning or documentation purposes.</li> </ul>"},{"location":"utilities/processes/strace/#conclusion","title":"Conclusion","text":"<p>The <code>strace</code> command is an indispensable tool for debugging and understanding the behavior of Linux programs. Whether you're troubleshooting a stubborn bug, analyzing a program's performance, or simply curious about how a program interacts with the system, <code>strace</code> provides deep insights into the underlying system calls. For more detailed usage, refer to the <code>man strace</code> page or explore additional resources like the linked strace guide.</p>"},{"location":"utilities/services/System%20management/","title":"System management","text":""},{"location":"utilities/services/System%20management/#guide-to-system-monitoring-and-management-commands-in-linux-and-macos","title":"Guide to System Monitoring and Management Commands in Linux and macOS","text":"<p>This guide provides an overview of key utilities for managing system services and monitoring logs in Linux and macOS. We'll cover <code>systemctl</code>, <code>journalctl</code>, <code>service</code>, and <code>brew</code>, including practical examples of commonly used commands. The guide is divided into two sections based on the operating system: Linux and macOS.</p>"},{"location":"utilities/services/System%20management/#linux-system-monitoring-and-management","title":"Linux System Monitoring and Management","text":""},{"location":"utilities/services/System%20management/#1-systemctl","title":"1. <code>systemctl</code>","text":"<p>Description: <code>systemctl</code> is the primary tool for managing system services in Linux distributions that use <code>systemd</code> as their init system. It controls the state of services, enables/disables them at startup, and checks their status.</p> <p>Basic Usage:</p> <ul> <li>Start a Service:</li> </ul> <p><code>bash   sudo systemctl start &lt;service_name&gt;</code></p> <ul> <li>Stop a Service:</li> </ul> <p><code>bash   sudo systemctl stop &lt;service_name&gt;</code></p> <ul> <li>Restart a Service:</li> </ul> <p><code>bash   sudo systemctl restart &lt;service_name&gt;</code></p> <ul> <li>Enable a Service at Boot:</li> </ul> <p><code>bash   sudo systemctl enable &lt;service_name&gt;</code></p> <ul> <li>Disable a Service at Boot:</li> </ul> <p><code>bash   sudo systemctl disable &lt;service_name&gt;</code></p> <ul> <li>Check the Status of a Service:</li> </ul> <p><code>bash   sudo systemctl status &lt;service_name&gt;</code></p> <ul> <li>List All Services:</li> </ul> <p><code>bash   systemctl list-units --type=service</code></p> <p>Example:</p> <pre><code>sudo systemctl status nginx\n</code></pre> <p>This command checks the status of the <code>nginx</code> service, showing whether it's active, its process ID, and any recent logs.</p>"},{"location":"utilities/services/System%20management/#2-journalctl","title":"2. <code>journalctl</code>","text":"<p>Description: <code>journalctl</code> is a command used to view logs collected by the <code>systemd</code> journal. It provides access to logs generated by <code>systemd</code> services and the kernel.</p> <p>Basic Usage:</p> <ul> <li>View Recent Logs:</li> </ul> <p><code>bash   sudo journalctl -n 50</code></p> <ul> <li> <p><code>-n 50</code>: Shows the last 50 log entries.</p> </li> <li> <p>View Logs for a Specific Service:</p> </li> </ul> <p><code>bash   sudo journalctl -u &lt;service_name&gt;</code></p> <ul> <li>Follow Logs in Real-Time:</li> </ul> <p><code>bash   sudo journalctl -f</code></p> <ul> <li>View Logs from the Last Boot:</li> </ul> <p><code>bash   sudo journalctl -b</code></p> <p>Advanced Example:</p> <pre><code>sudo journalctl -xn 50 -u chef-client --no-pager\n</code></pre> <ul> <li><code>-x</code>: Adds extra information where available.</li> <li><code>-n 50</code>: Shows the last 50 log entries.</li> <li><code>-u chef-client</code>: Filters logs for the <code>chef-client</code> service.</li> <li><code>--no-pager</code>: Outputs the log without using a pager, so it displays directly in the terminal.</li> </ul> <p>This command is particularly useful for troubleshooting issues with specific services.</p>"},{"location":"utilities/services/System%20management/#3-service","title":"3. <code>service</code>","text":"<p>Description: <code>service</code> is a command used to manage services on systems that may not use <code>systemd</code> (though it can still be found on <code>systemd</code> systems). It provides a way to start, stop, restart, and check the status of services.</p> <p>Basic Usage:</p> <ul> <li>Start a Service:</li> </ul> <p><code>bash   sudo service &lt;service_name&gt; start</code></p> <ul> <li>Stop a Service:</li> </ul> <p><code>bash   sudo service &lt;service_name&gt; stop</code></p> <ul> <li>Restart a Service:</li> </ul> <p><code>bash   sudo service &lt;service_name&gt; restart</code></p> <ul> <li>Check the Status of a Service:</li> </ul> <p><code>bash   sudo service &lt;service_name&gt; status</code></p> <p>Example:</p> <pre><code>sudo service apache2 restart\n</code></pre> <p>This command restarts the <code>apache2</code> service.</p>"},{"location":"utilities/services/System%20management/#macos-system-monitoring-and-management","title":"macOS System Monitoring and Management","text":""},{"location":"utilities/services/System%20management/#1-brew","title":"1. <code>brew</code>","text":"<p>Description: <code>brew</code> is the package manager for macOS, also known as Homebrew. It allows you to install, update, and manage software packages and services on macOS.</p> <p>Basic Usage:</p> <ul> <li>Install a Package:</li> </ul> <p><code>bash   brew install &lt;package_name&gt;</code></p> <ul> <li>Uninstall a Package:</li> </ul> <p><code>bash   brew uninstall &lt;package_name&gt;</code></p> <ul> <li>List Installed Packages:</li> </ul> <p><code>bash   brew list</code></p> <p>Managing Services with Homebrew:</p> <p>Homebrew can also manage services (like databases, web servers, etc.) using the <code>brew services</code> command.</p> <ul> <li>List All Services:</li> </ul> <p><code>bash   brew services list</code></p> <ul> <li>Start a Service:</li> </ul> <p><code>bash   brew services start &lt;service_name&gt;</code></p> <ul> <li>Stop a Service:</li> </ul> <p><code>bash   sudo brew services stop &lt;service_name&gt;</code></p> <ul> <li>Restart a Service:</li> </ul> <p><code>bash   brew services restart &lt;service_name&gt;</code></p> <p>Example:</p> <pre><code>brew services list\nsudo brew services stop nginx\n</code></pre> <ul> <li><code>brew services list</code>: Lists all services managed by Homebrew, showing their status.</li> <li><code>sudo brew services stop nginx</code>: Stops the <code>nginx</code> service.</li> </ul>"},{"location":"utilities/services/System%20management/#summary","title":"Summary","text":"<p>This guide covers essential commands for managing and monitoring system services in Linux and macOS environments. </p>"},{"location":"utilities/services/System%20management/#linux","title":"Linux:","text":"<ul> <li><code>systemctl</code> and <code>service</code> are the primary tools for managing services, while <code>journalctl</code> is used for log monitoring.</li> </ul>"},{"location":"utilities/services/System%20management/#macos","title":"macOS:","text":"<ul> <li><code>brew</code> is the package manager, and <code>brew services</code> provides a convenient way to manage background services.</li> </ul>"},{"location":"utilities/services/Systemd%20service/","title":"Systemd service","text":""},{"location":"utilities/services/Systemd%20service/#viewing-the-full-content-of-a-systemd-service-with-systemctl-cat","title":"Viewing the Full Content of a Systemd Service with <code>systemctl cat</code>","text":"<p>The <code>systemctl cat</code> command is a powerful and useful feature of <code>systemctl</code> that allows you to view the full content of a systemd service unit file, including any drop-in configuration files that override or extend the default settings.</p>"},{"location":"utilities/services/Systemd%20service/#purpose-of-systemctl-cat","title":"Purpose of <code>systemctl cat</code>","text":"<p>When you run <code>systemctl cat &lt;service_name&gt;</code>, it displays the contents of the main unit file along with any additional configuration files located in the <code>/etc/systemd/system/&lt;service_name&gt;.service.d/</code> directory. This command is particularly useful for debugging or understanding how a service is configured, especially when changes have been made using drop-in files.</p>"},{"location":"utilities/services/Systemd%20service/#example-usage","title":"Example Usage","text":"<p>Suppose you want to inspect the <code>puppet</code> service unit file, including any modifications or overrides that might be in place. You would run the following command:</p> <pre><code>sudo systemctl cat puppet\n</code></pre>"},{"location":"utilities/services/Systemd%20service/#sample-output-explanation","title":"Sample Output Explanation","text":"<pre><code>sudo systemctl cat puppet\n</code></pre> <p>Output:</p> <pre><code># /lib/systemd/system/puppet.service\n#\n# Local settings can be configured without being overwritten by package upgrades, for example\n# if you want to increase puppet open-files-limit to 10000,\n# you need to increase systemd's LimitNOFILE setting, so create a file named\n# \"/etc/systemd/system/puppet.service.d/limits.conf\" containing:\n# [Service]\n# LimitNOFILE=10000\n# You can confirm it worked by running systemctl daemon-reload\n# then running systemctl show puppet | grep LimitNOFILE\n#\n[Unit]\nDescription=Puppet agent\nWants=basic.target\nAfter=basic.target network.target\n\n[Service]\nEnvironmentFile=-/etc/sysconfig/puppetagent\nEnvironmentFile=-/etc/sysconfig/puppet\nEnvironmentFile=-/etc/default/puppet\nExecStart=/opt/puppetlabs/puppet/bin/puppet agent $PUPPET_EXTRA_OPTS --no-daemonize\nExecReload=/bin/kill -HUP $MAINPID\nKillMode=process\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>Explanation:</p> <ul> <li> <p>Main Unit File:   The output shows the contents of the main unit file located at <code>/lib/systemd/system/puppet.service</code>. This file is provided by the package and contains the default configuration for the <code>puppet</code> service.</p> </li> <li> <p>Configuration File Locations:</p> </li> <li>EnvironmentFile: The <code>EnvironmentFile</code> entries reference external files (<code>/etc/sysconfig/puppetagent</code>, <code>/etc/sysconfig/puppet</code>, and <code>/etc/default/puppet</code>) that can set environment variables for the service. The <code>-</code> prefix means that these files are optional; the service will still start if they are not found.</li> <li>ExecStart: Specifies the command to start the service. In this case, it runs the Puppet agent with any additional options defined by <code>$PUPPET_EXTRA_OPTS</code>.</li> <li>ExecReload: Specifies the command to reload the service without stopping it, typically sending a signal to the main process.</li> <li> <p>KillMode: Defines how processes are terminated when the service is stopped.</p> </li> <li> <p>Custom Configuration:</p> </li> <li>The commented section explains how to create a custom configuration file, <code>/etc/systemd/system/puppet.service.d/limits.conf</code>, to increase the <code>LimitNOFILE</code> setting (which controls the maximum number of open files). This custom configuration will not be overwritten during package upgrades, as it's stored in the <code>/etc</code> directory.</li> </ul>"},{"location":"utilities/services/Systemd%20service/#modifying-and-extending-service-configurations","title":"Modifying and Extending Service Configurations","text":"<p>To modify or extend the configuration of a systemd service without altering the original unit file, you can create drop-in configuration files in the <code>/etc/systemd/system/&lt;service_name&gt;.service.d/</code> directory.</p> <p>Example:</p> <p>To increase the <code>LimitNOFILE</code> for the <code>puppet</code> service:</p> <ol> <li>Create a Drop-In Directory:</li> </ol> <p><code>bash    sudo mkdir -p /etc/systemd/system/puppet.service.d/</code></p> <ol> <li>Create a Drop-In Configuration File:</li> </ol> <p><code>bash    sudo nano /etc/systemd/system/puppet.service.d/limits.conf</code></p> <ol> <li>Add the Configuration:</li> </ol> <pre><code>   [Service]\n   LimitNOFILE=10000\n</code></pre> <ol> <li>Reload systemd Configuration:</li> </ol> <p>After saving the file, reload the systemd configuration to apply the changes:</p> <p><code>bash    sudo systemctl daemon-reload</code></p> <ol> <li>Verify the Change:</li> </ol> <p>You can verify that the change took effect by running:</p> <p><code>bash    systemctl show puppet | grep LimitNOFILE</code></p> <p>This command will show the current <code>LimitNOFILE</code> setting for the <code>puppet</code> service, confirming that your configuration change has been applied.</p>"},{"location":"utilities/services/Systemd%20service/#summary","title":"Summary","text":"<p>The <code>systemctl cat</code> command is an excellent tool for inspecting service unit files, including any custom modifications made through drop-in configurations. This approach is crucial for managing services in a way that ensures your custom configurations are preserved across system updates and service changes. By using <code>systemctl cat</code>, you gain full visibility into how a service is configured, making it easier to diagnose issues, make adjustments, and understand the service's behavior on your system.</p>"},{"location":"utilities/services/supervisord/","title":"Supervisor \u2013 Managing Processes and Services","text":"<p>Supervisor is a powerful tool for managing and monitoring processes and services in Unix-like operating systems. It allows you to control your services, ensuring they are always running and can be restarted if they fail.</p>"},{"location":"utilities/services/supervisord/#key-features-of-supervisor","title":"Key Features of Supervisor","text":"<ul> <li>Process Monitoring: Supervisor can automatically restart processes that fail, ensuring high availability.</li> <li>Simple Configuration: Configuration files are written in a simple INI-style format, making them easy to understand and manage.</li> <li>Web Interface: An optional web-based interface allows for easy management and monitoring of processes.</li> <li>Logging: Supervisor provides detailed logging for each managed process, which is crucial for debugging and monitoring.</li> <li>Process Grouping: Allows you to group related processes, so they can be managed together (e.g., starting or stopping a group of processes at once).</li> </ul>"},{"location":"utilities/services/supervisord/#installing-supervisor","title":"Installing Supervisor","text":"<p>To install Supervisor on a Debian-based system (such as Ubuntu), use the following command:</p> <pre><code>sudo apt-get install supervisor\n</code></pre> <p>On CentOS or RHEL-based systems, you can install Supervisor using:</p> <pre><code>sudo yum install supervisor\n</code></pre>"},{"location":"utilities/services/supervisord/#configuring-supervisor","title":"Configuring Supervisor","text":"<p>Supervisor\u2019s configuration files are located in the <code>/etc/supervisor/</code> directory. The main configuration file is <code>supervisord.conf</code>, and individual process configurations are stored in the <code>/etc/supervisor/conf.d/</code> directory.</p>"},{"location":"utilities/services/supervisord/#example-configuration","title":"Example Configuration","text":"<p>Here\u2019s an example of a Supervisor configuration file for managing a simple Python application:</p> <pre><code>[program:myapp]\ncommand=/usr/bin/python /path/to/app.py\nautostart=true\nautorestart=true\nstderr_logfile=/var/log/myapp/myapp.err.log\nstdout_logfile=/var/log/myapp/myapp.out.log\n</code></pre> <ul> <li>command: Specifies the command to start the program.</li> <li>autostart: Ensures that the program starts automatically when Supervisor starts.</li> <li>autorestart: Configures the program to restart automatically if it exits unexpectedly.</li> <li>stderr_logfile and stdout_logfile: Define the log files for capturing standard error and output.</li> </ul>"},{"location":"utilities/services/supervisord/#starting-supervisor","title":"Starting Supervisor","text":"<p>After configuring your processes, you can start Supervisor using:</p> <pre><code>sudo service supervisor start\n</code></pre> <p>Or, on systems using <code>systemd</code>:</p> <pre><code>sudo systemctl start supervisor\n</code></pre>"},{"location":"utilities/services/supervisord/#managing-processes-with-supervisor","title":"Managing Processes with Supervisor","text":"<p>You can manage your processes using the <code>supervisorctl</code> command:</p> <ul> <li>Start a Process:</li> </ul> <p><code>bash   sudo supervisorctl start myapp</code></p> <ul> <li>Stop a Process:</li> </ul> <p><code>bash   sudo supervisorctl stop myapp</code></p> <ul> <li>Restart a Process:</li> </ul> <p><code>bash   sudo supervisorctl restart myapp</code></p> <ul> <li>Check the Status of a Process:</li> </ul> <p><code>bash   sudo supervisorctl status myapp</code></p> <ul> <li>View Logs:</li> </ul> <p>You can view the logs of a managed process directly from the log files defined in the configuration or by using Supervisor\u2019s logging command:</p> <p><code>bash   sudo supervisorctl tail -f myapp</code></p>"},{"location":"utilities/services/supervisord/#using-the-web-interface","title":"Using the Web Interface","text":"<p>Supervisor comes with an optional web interface that you can enable for easier process management. To enable it, add the following section to your <code>supervisord.conf</code>:</p> <pre><code>[inet_http_server]\nport=*:9001\nusername=user\npassword=pass\n</code></pre> <ul> <li>port: Defines the port where the web interface will be accessible.</li> <li>username and password: Set the credentials for accessing the web interface.</li> </ul> <p>After making these changes, restart Supervisor to apply the configuration:</p> <pre><code>sudo supervisorctl reload\n</code></pre> <p>You can now access the web interface by navigating to <code>http://&lt;your-server-ip&gt;:9001</code> in your web browser.</p>"},{"location":"utilities/services/supervisord/#conclusion","title":"Conclusion","text":"<p>Supervisor is an essential tool for anyone managing services and processes on a Linux system. It provides robust features for ensuring that your processes are always running and easily manageable. For more detailed instructions and advanced configurations, you can refer to this article.</p>"},{"location":"virtualization/Docker/","title":"Docker","text":""},{"location":"virtualization/Docker/#docker-networking","title":"Docker Networking","text":"<p>Docker provides several networking modes to enable communication between containers and the outside world. Understanding these modes is crucial for setting up and managing containerized applications.</p>"},{"location":"virtualization/Docker/#1-bridge-network-default","title":"1. Bridge Network (Default)","text":"<ul> <li>Description: The default networking mode where containers communicate with each other using their IP addresses on an isolated bridge network.</li> <li>Use Case: Ideal for simple, single-host deployments where containers need to communicate internally.</li> <li>Example: When you start a container without specifying a network, it automatically connects to the default bridge network.</li> </ul>"},{"location":"virtualization/Docker/#2-host-network","title":"2. Host Network","text":"<ul> <li>Description: The container shares the host\u2019s network stack, meaning it has direct access to the host\u2019s network interfaces.</li> <li>Use Case: Useful for performance-sensitive applications where minimizing network latency is critical.</li> <li>Example:    <code>bash   docker run --network host mycontainer</code></li> </ul>"},{"location":"virtualization/Docker/#3-overlay-network","title":"3. Overlay Network","text":"<ul> <li>Description: Allows containers running on different Docker hosts to communicate securely. Typically used in multi-host Docker Swarm or Kubernetes setups.</li> <li>Use Case: Essential for distributed applications that require communication across multiple hosts.</li> <li>Example: Docker Swarm creates an overlay network automatically for services.</li> </ul>"},{"location":"virtualization/Docker/#4-macvlan-network","title":"4. Macvlan Network","text":"<ul> <li>Description: Assigns a MAC address to each container, making them appear as physical devices on the network.</li> <li>Use Case: Useful when you need containers to be treated as real devices on the physical network.</li> <li>Example:   <code>bash   docker network create -d macvlan --subnet=192.168.1.0/24 mymacvlan</code></li> </ul>"},{"location":"virtualization/Docker/#5-none-network","title":"5. None Network","text":"<ul> <li>Description: The container has no network interfaces, effectively isolating it from any network.</li> <li>Use Case: Security-focused scenarios where network isolation is required.</li> <li>Example:   <code>bash   docker run --network none mycontainer</code></li> </ul> <p>Important Note: When using Docker Swarm, you may encounter the \"network not manually attachable\" error when running a one-off command. This occurs because Swarm\u2019s overlay networks are not manually attachable unless explicitly configured during creation. More details can be found in this StackOverflow discussion.</p>"},{"location":"virtualization/Docker/#cmd-vs-entrypoint-in-docker","title":"CMD vs ENTRYPOINT in Docker","text":"<p>Docker provides two main instructions for defining the command that runs when a container starts: <code>CMD</code> and <code>ENTRYPOINT</code>. While they appear similar, they serve distinct purposes.</p>"},{"location":"virtualization/Docker/#1-cmd","title":"1. CMD","text":"<ul> <li>Description: Specifies the default command to execute when the container starts. It can be overridden by passing a different command when running the container.</li> <li>Use Case: Best used for providing default arguments to an entrypoint or for simple commands that might change at runtime.</li> <li>Example:   <code>bash   docker run myimage [command] [args]</code>   This command overrides the default <code>CMD</code> defined in the Dockerfile.</li> </ul>"},{"location":"virtualization/Docker/#2-entrypoint","title":"2. ENTRYPOINT","text":"<ul> <li>Description: Defines the command that will always run within the container. Unlike <code>CMD</code>, it cannot be overridden without the <code>--entrypoint</code> flag.</li> <li>Use Case: Useful when you need to ensure a specific command always runs, regardless of what command is provided at runtime.</li> <li>Example:   <code>bash   docker run --entrypoint [my_entrypoint] myimage</code>   This command overrides the <code>ENTRYPOINT</code> defined in the Dockerfile.</li> </ul> <p>Key Difference: <code>ENTRYPOINT</code> is designed to ensure a specific command always runs, while <code>CMD</code> is more flexible and can be overridden. For a deeper dive, check out this Habr article.</p>"},{"location":"virtualization/Docker/#multi-architecture-docker-images-with-buildx","title":"Multi-Architecture Docker Images with Buildx","text":"<p>Docker Buildx is an advanced tool that allows you to build Docker images for multiple architectures (such as ARM and x86) from a single Dockerfile.</p>"},{"location":"virtualization/Docker/#1-enabling-experimental-features","title":"1. Enabling Experimental Features","text":"<ul> <li>Description: To use Buildx, Docker\u2019s experimental features must be enabled.</li> <li>Use Case: Necessary for enabling advanced Docker capabilities like multi-architecture builds.</li> <li>Example: Instructions for enabling experimental features can be found here.</li> </ul>"},{"location":"virtualization/Docker/#2-setting-up-buildx","title":"2. Setting Up Buildx","text":"<ul> <li>Description: Buildx extends Docker with the ability to build multi-platform images.</li> <li>Use Case: Essential for developing applications that need to run on different CPU architectures.</li> <li>Example:   <code>bash   docker buildx create --use   docker buildx build --platform linux/amd64,linux/arm64 -t yourimage:latest --push .</code></li> </ul>"},{"location":"virtualization/Docker/#3-building-multi-architecture-images","title":"3. Building Multi-Architecture Images","text":"<ul> <li>Description: Use Buildx to build and push Docker images for multiple architectures from a single Dockerfile.</li> <li>Use Case: Useful for deploying containers across various hardware platforms.</li> <li>Example:   <code>bash   docker buildx build --platform linux/amd64,linux/arm64 -t yourimage:latest --push .</code></li> </ul>"},{"location":"virtualization/Docker/#resources","title":"Resources:","text":"<ul> <li>Getting Started with Docker for ARM on Linux</li> <li>Building Multi-Architecture Docker Images with Buildx</li> <li>Docker ARM Support with Buildx and Emulator</li> </ul> <p>This guide provides a comprehensive overview of Docker networking, the differences between <code>CMD</code> and <code>ENTRYPOINT</code>, and how to work with multi-architecture Docker images using Buildx. Whether you\u2019re deploying simple containers or complex multi-architecture applications, these tools and techniques will help you get the most out of Docker.</p>"}]}